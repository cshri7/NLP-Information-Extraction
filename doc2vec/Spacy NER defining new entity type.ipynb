{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sentences.csv', header=None, delimiter=';', error_bad_lines=False, names=['website','text', 'keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from ast import literal_eval\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "    norm_text = norm_text.replace('<br />', '')\n",
    "    norm_text = re.sub(r\"([\\.\\\",\\(\\)!\\?;:])\", \"\\\\1\", norm_text)\n",
    "    norm_text = ' '.join(norm_text.split())\n",
    "    return norm_text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return \" \".join([item.lower() for item in text.split() if item not in stop])\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    return ''.join([\"\" if ord(i) < 32 or ord(i) > 126 else i for i in text])\n",
    "\n",
    "df['text'] = df['text'].apply(remove_non_ascii)\n",
    "df['text'] = df['text'].apply(normalize_text)\n",
    "#df['text'] = df['text'].apply(remove_stop_words)\n",
    "df[\"text\"] = df['text'].str.replace('[^\\w\\s]','')\n",
    "df['keywords'] = df['keywords'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "result = []\n",
    "for index, row in df.iterrows():\n",
    "    ret_dic = {}\n",
    "    ret_dic['entities'] = []\n",
    "    ret_sentence = row.text\n",
    "    for keyword in row.keywords:\n",
    "        keyword = keyword.lower()\n",
    "        ret_dic['entities'].extend([(m.start(), m.end(), \"THREAT_GROUP\") for m in re.finditer(keyword, row.text)])\n",
    "    result.append((ret_sentence, ret_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "\n",
    "def main(new_model_name='threat_test', n_iter=20, LABEL = \"THREAT_GROUP\"):\n",
    "    #nlp = spacy.load('en_core_web_sm')\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    #print(\"Created blank 'en' model\")\n",
    "    \n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner)\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    ner.add_label(LABEL)\n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            batches = minibatch(TRAIN_DATA, size=compounding(4., 32., 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35,\n",
    "                           losses=losses)\n",
    "            print('Losses', losses)\n",
    "\n",
    "    test_text = 'apt3 also known as ups gothic panda tg-011 is a sophisticated threat group that has been active since at least 2010'\n",
    "    doc = nlp(test_text)\n",
    "    print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label_, ent.text)\n",
    "\n",
    "    doc = nlp(test_text)\n",
    "    displacy.serve(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Losses {u'ner': 45.616202465517524}\n",
      "Losses {u'ner': 34.501424441126616}\n",
      "Losses {u'ner': 26.612149420847842}\n",
      "Losses {u'ner': 19.47262269989022}\n",
      "Losses {u'ner': 14.86779618980406}\n",
      "Losses {u'ner': 11.543234692413737}\n",
      "Losses {u'ner': 9.981635776888385}\n",
      "Losses {u'ner': 6.078508888126309}\n",
      "Losses {u'ner': 6.589563756615391}\n",
      "Losses {u'ner': 5.462666871891496}\n",
      "Losses {u'ner': 3.423468109031284}\n",
      "Losses {u'ner': 3.184500525871258}\n",
      "Losses {u'ner': 3.477061922782298}\n",
      "Losses {u'ner': 2.8875157847607555}\n",
      "Losses {u'ner': 2.468300917949294}\n",
      "Losses {u'ner': 1.8711684199720249}\n",
      "Losses {u'ner': 1.8899188461321006}\n",
      "Losses {u'ner': 1.559912711816471}\n",
      "Losses {u'ner': 1.8805002857553175}\n",
      "Losses {u'ner': 0.8610457257382147}\n",
      "Entities in 'apt3 also known as ups gothic panda tg-011 is a sophisticated threat group that has been active since at least 2010'\n",
      "THREAT_GROUP apt3\n",
      "THREAT_GROUP ups\n",
      "THREAT_GROUP gothic\n",
      "THREAT_GROUP panda\n",
      "THREAT_GROUP tg-011\n",
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'ent' visualizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Dec/2018 15:45:59] \"GET / HTTP/1.1\" 200 2474\n",
      "127.0.0.1 - - [02/Dec/2018 15:46:00] \"GET /favicon.ico HTTP/1.1\" 200 2474\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
