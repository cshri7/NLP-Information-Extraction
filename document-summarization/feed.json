[
 {
  "content": "East African ML Needs, Autonomy Corrections, Information Security, and UIs from Doodles\n\nSome Requests for Machine Learning Research from the East African Tech Scene -- Based on 46 indepth interviews [...] a list of concrete machine learning research problems, progress on which would directly benefit tech ventures in East Africa. Example: Priors for autocorrect and low-literacy SMS useSMS text contains many language misuses due to a combination of autocorrection and low literacy. E.g., poultry farmer becoming poetry farmer. Such mistakes are bound to occur in any written language corpus, but engineers working with rural populations in East Africa report that this is a prevalent issue for them, confounding the  use of pretrained language models. This problem also exists to some degree in voice data with respect to English spoken in different accents. Priors over autocorrect substitution rules, or custom, perdialect confusion matrices between phonetically similar words could potentially help. Expect much more work like this as AI/ML moves into non-WEIRD (Western Educated Industrialized Rich Democratic) nations.\n\nHow the Media Gets Tesla Wrong -- a reminder that our convenient shorthand and once-over-lightly reading of the news gives a false and rosy picture of what's possible.\n\nWhy Information Security is Hard: An Economic Perspective -- fascinating arguments! I particularly like the statistical argument: a lone attacker might find 10 bugs a year, a well-prepared defender might find 1,000 bugs a year, but if there are 100,000 available bugs for exploitation, then there's very low probability that the defender found and patched the same bugs that the attacker found...\n\nDoodleMaster -- sketches->UI via a CNN, a proof-of-concept.\n\nContinue reading Four short links: 20 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/fyCV72kicf0/four-short-links-20-november-2018", 
  "title": "Four short links: 20 November 2018"
 }, 
 {
  "content": "Partial Time, Black Mirror, Implant Usability, and Open Source Game\n\nTime is Partial -- Even though time naturally feels like a total order, studying distributed systems or weak memory exposes you, head on, to how it isnt. And thats precisely because these are both cases where our standard over-approximation of time being total limits performancewhich we obviously cant have.\n\n\nBlack Mirror, Light Mirror: Teaching Technology Ethics Through Speculation (Casey Fiesler) -- This is not a new idea, and Im certainly not the only one to do a lot of thinking about it (e.g., see How to Teach Computer Ethics Through Science Fiction), but I wanted to share two specific exercises that I use and that I think are easily adaptable.\n\n\nHow I Lost and Regained Control of My Microchip Implant (Vice) -- After a year of living with a totally useless NFC implant, I kind of started to like it. That small, almost imperceptible little bump on my left hand was a constant reminder that even the most sophisticated and fool-proof technologies are no match for human incompetence. (via Slashdot)\n\nSystem Syzygy -- open source puzzle game for Mac, Windows, and Linux. (via Andrew Plotkin)\n\nContinue reading Four short links: 19 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/lMQPGkVuKgE/four-short-links-19-november-2018", 
  "title": "Four short links: 19 November 2018"
 }, 
 {
  "content": "Our most-used Java resources will help you stay on track in your journey to learn and apply Java.We dove into the data on our online learning platform to identify the most-used Java resources. These are the items our platform subscribers regularly turn to as they apply Java in their projects and organizations.\nEffective Java, 3rd Edition  Joshua Bloch covers language and library features added in Java 7, 8, and 9, including the functional programming constructs that were added to its object-oriented roots. Many new items have been added, including a chapter devoted to lambdas and streams.\nJava 8 and 9 Fundamentals: Modern Java Development with Lambdas, Streams, and Introducing Java 9s JShell and the Java Platform Module System (JPMS)  Paul Deitel applies the Deitel signature live-code approach to teaching programming and explores the Java language and Java APIs in depth.\nJava 8 in Action: Lambdas, streams, and functional-style programming  Raoul-Gabriel Urma, Mario Fusco, and Alan Mycroft cover lambdas, streams, and functional-style programming in this clearly written guide to to the new features of Java 8.\nHead First Java, 2nd Edition  Bert Bates and Kathy Sierra offer a complete introduction to object-oriented programming and Java.\nOCP Oracle Certified Professional Java SE 8 Programmer II  Scott Selikoff and Jeanne Boyarsky bring you a comprehensive companion for preparing for Exam 1Z0-809 as well as upgrade Exam 1Z0-810 and Exam 1Z0-813.\nJava Concurrency in Practice  This book arms readers with both the theoretical underpinnings and concrete techniques for building reliable, scalable, maintainable concurrent applications.\nOptimizing Java  Chris Newland, James Gough, and Benjamin Evans teach you how to tune Java applications for performance using a quantitative, verifiable approach.\nJava: The Complete Reference, 10th Edition  Herbert Schildt covers the entire Java language, including its syntax, keywords, and fundamental programming principles.\nJava for Beginners: Step-by-Step Hands-On Guide to Java  Manuj Aggarwal and the TetraTutorials Team bring you a course jam-packed with practical demos, homework assignments, and live coding to help you grasp the complex topics.\nCloud Native Java  Josh Long and Kenny Bastani show Java/JVM developers how to build better software, faster, using Spring Boot, Spring Cloud, and Cloud Foundry.\nContinue reading 10 top Java resources on OReillys online learning platform.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/9qJvvWFH3J4/10-top-java-resources-on-oreillys-online-learning-platform", 
  "title": "10 top Java resources on O\u2019Reilly\u2019s online learning platform"
 }, 
 {
  "content": "Illuminated Paper, Software Forge, Leak Checklist, and PC on ESP\n\nIllumiPaper -- illuminated elements built into regular paper, with implementation.\n\nsr.ht -- (pronounced \"sir hat\") a software forge like GitHub or GitLab, but with interesting strengths (e.g., very lightweight pages, and the CI system).\n\nLeak Mitigation Checklist -- If you just leaked sensitive information in public source code, read this document as part of your emergency procedure.\n\n\nEmulating an IBM PC on an ESP8266 -- an 8086 PC-XT emulation with 640K RAM, 8025 CGA composite video, and a 1.44MB MS-DOS disk on an ESP12E without additional components. (via Alasdair Allen)\n\nContinue reading Four short links: 16 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/GCzDYWHwnqY/four-short-links-16-november-2018", 
  "title": "Four short links: 16 November 2018"
 }, 
 {
  "content": "Punish Online Criminals, Fake Fingerprints, Implementing Identity, and Project Visbug\n\nUSA Needs to Pursue Malicious Cyber Actors -- a report that argues that the United States currently lacks a comprehensive overarching strategic approach to identify, stop, and punish cyberattackers. (1) There is a burgeoning cybercrime wave. (2) There is a stunning cyber enforcement gap. (3) There is no comprehensive U.S. cyber enforcement strategy aimed at the human attacker. This is definitely a golden age of online crime.\n\nDeepMasterPrints: Generating MasterPrints for Dictionary Attacks via Latent Variable Evolution -- MasterPrints are real or synthetic fingerprints that can fortuitously match with a large number of fingerprints, thereby undermining the security afforded by fingerprint systems. Previous work by Roy, et al., generated synthetic MasterPrints at the feature level. In this work, we generate complete image-level MasterPrints known as DeepMasterPrints, whose attack accuracy is found to be much superior than that of previous methods. (via Mikko Hypponen)\n\nThe Tripartite Identity Pattern (Randy Farmer) -- The three components of user identity are: the account identifier, the login identifier, and the public identifier.\n\n\nProject VisBug -- edit/tweak existing webpages.\n\nContinue reading Four short links: 15 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/PetAndga-uQ/four-short-links-15-november-2018", 
  "title": "Four short links: 15 November 2018"
 }, 
 {
  "content": "ML Risk, IGF Session, Feature Engineering, and Solving Snake\n\nManaging Risk in Machine Learning Projects (Ben Lorica) -- Considerations for a world where ML models are becoming mission critical.\n\n\nTranscripts of 2018 IGF -- Internet Governance Forum session transcripts.\n\nFeaturetools -- open source Python framework for automated feature engineering.\n\nSolving Snake -- fun exploration of different algorithms you might use to play the Snake game.\n\nContinue reading Four short links: 14 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/DlnePzjJb7M/four-short-links-14-november-2018", 
  "title": "Four short links: 14 November 2018"
 }, 
 {
  "content": "Ways of Working, Too-Smart AI, Wi-Fi Vision, and Materials Science AI\n\nInternet-Era Ways of Working -- an elegant brief summary of how we do software in 2018, from Tom Loosemore's public.digital team.\n\nExamples of AI Gaming the System -- a list of examples of AIs learning more than was intended. Neural nets evolved to classify edible and poisonous mushrooms, took advantage of the data being presented in alternating order, and didn't actually learn any features of the input images. (via BoingBoing)\n\nUsing Wi-Fi to See Behind Closed Doors is Easier than Anyone Thought (MIT TR) -- if all you are interested in is the movement of people. Humans also reflect and distort this Wi-Fi light. The distortion, and the way it moves, would be clearly visible through Wi-Fi eyes, even though the other details would be smeared. This crazy Wi-Fi vision would clearly reveal whether anybody was behind a wall and, if so, whether the person was moving. Thats the basis of Zhu and cos Wi-Fi-based peeping tom. It looks for changes in an ordinary Wi-Fi signal that reveal the presence of humans.\n\n\nLearning Process-Structure-Property Relations -- clever research project that mines research literature to learn relationships about the physical properties and processes in materials science, then automatically generates a diagam for the particular constraints your project has. Code released as open source.\n\nContinue reading Four short links: 13 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/3rt_Kca32HQ/four-short-links-13-november-2018", 
  "title": "Four short links: 13 November 2018"
 }, 
 {
  "content": "Considerations for a world where ML models are becoming mission critical.In this post, I share slides and notes from a keynote I gave at the Strata Data Conference in New York last September. As the data community begins to deploy more machine learning (ML) models, I wanted to review some important considerations.\nLets begin by looking at the state of adoption. We recently conducted a survey which garnered more than 11,000 respondentsour main goal was to ascertain how enterprises were using machine learning. One of the things we learned was that many companies are still in the early stages of deploying machine learning (ML):\n\nAs far as reasons for companies holding back, we found from a survey we conducted earlier this year that companies cited lack of skilled people, a skills gap, as the main challenge holding back adoption.\nInterest on the part of companies means the demand side for machine learning talent is healthy. Developers have taken notice and are beginning to learn about ML. In our own online training platform (which has more than 2.1 million users), were finding strong interest in machine learning topics. Below are the top search topics on our training platform:\n\nBeyond search, note that were seeing strong growth in consumption of content related to ML across all formatsbooks, posts, video, and training.\nBefore I continue, its important to emphasize that machine learning is much more than building models. You need to have the culture, processes, and infrastructure in place before you can deploy many models into products and services. At the recent Strata Data conference we had a series of talks on relevant cultural, organizational, and engineering topics. Here's a list of a few clusters of relevant sessions from the recent conference:\n\nData Integration and Data Pipelines\nData Platforms\nModel lifecycle management\n\nOver the last 12-18 months, companies that use a lot of ML and employ teams of data scientists have been describing their internal data science platforms (see, for example, Uber, Netflix, Twitter, and Facebook). They share some of the features I list below, including support for multiple ML libraries and frameworks, notebooks, scheduling, and collaboration. Some companies include advanced capabilities, including a way for data scientists to share features used in ML models, tools that can automatically search through potential models, and some platforms even have model deployment capabilities:\n\nAs you get beyond prototyping and you actually begin to deploy ML models, there are many challenges that will arise as those models begin to interact with real users or devices. David Talby summarized some of these key challenges in a recent post:\n\nYour models may start degrading in accuracy\nModels will need to be customized (for specific locations, cultural settings, domains, and applications)\nReal modeling begins once in production\n\nThere are also many important considerations that go beyond optimizing a statistical or quantitative metric. For instance, there are certain areassuch as credit scoring or health carethat require a model to be explainable. In certain application domains (including autonomous vehicles or medical applications), safety and error estimates are paramount. As we deploy ML in many real-world contexts, optimizing statistical or business metics alone will not suffice. The data science community has been increasingly engaged in two topics I want to cover in the rest of this post: privacy and fairness in machine learning.\nPrivacy and security\nGiven the growing interest in data privacy among users and regulators, there is a lot of interest in tools that will enable you to build ML models while protecting data privacy. These tools rely on building blocks, and we are beginning to see working systems that combine many of these building blocks. Some of these tools are open source and are becoming available for use by the broader data community:\n\n\n\nFederated learning is useful when you want to collaborate and build a centralized model without sharing private data. Its used in production at Google, but we still are in need of tools to make federated learning broadly accessible.\nWere starting to see tools that allow you to build models while guaranteeing differential privacy, one of the most popular and powerful definitions of privacy. At a high-level these methods inject random noise at different stages of the model building process. These emerging sets of tools aim to be accessible to data scientists who are already using libraries such as scikit-learn and TensorFlow. The hope is that data scientists will soon be able to routinely build differentially private models.\nTheres a small and growing number of researchers and entrepreneurs who are investigating whether we can build or use machine learning models on encrypted data. This past year, weve seen open source libraries (HElib and Palisade) for fast homomorphic encryption, and we have startups that are building machine learning tools and services on top of those libraries. The main bottleneck here is speed: many researchers are actively investigating hardware and software tools that can speed up model inference (and perhaps even model building) on encrypted data.\n\nSecure multi-party computation is another promising class of techniques used in this area.\n\nFairness\nNow lets consider fairness. Over the last couple of years, many ML researchers and practitioners have started investigating and developing tools that can help ensure ML models are fair and just. Just the other day, I searched Google for recent news stories about AI, and I was surprised by the number of articles that touch on fairness.\nFor the rest of this section, lets assume one is building a classifier and that certain variables are considered protected attributes (this can include things like age, ethnicity, gender, ...). It turns out that the ML research community has used numerous mathematical criteria to define what it means for a classifier to be fair. Fortunately, a recent survey paper from StanfordA Critical Review of Fair Machine Learningsimplifies these criteria and groups them into the following types of measures:\n\n\n\nAnti-classification means the omission of protected attributes and their proxies from the model or classifier.\n\nClassification parity means that one or more of the standard performance measures (e.g., false positive and false negative rates, precision, recall) are the same across groups defined by the protected attributes.\n\nCalibration: If an algorithm produces a score, that score should mean the same thing for different groups.\n\nHowever, as the authors from Stanford point out in their paper, each of the mathematical formulations described above suffers from limitations. With respect to fairness, there is no black box or series of procedures that you can stick your algorithm into that can give it a clean bill of health. There is no such thing as a one size, fits all procedure.\nBecause theres no ironclad procedure, you will need a team of humans-in-the-loop. Notions of fairness are not only domain and context sensitive, but as researchers from UC Berkeley recently pointed out, there is a temporal dimension as well (We advocate for a view toward long-term outcomes in the discussion of fair machine learning). What is needed are data scientists who can interrogate the data and understand the underlying distributions, working alongside domain experts who can evaluate models holistically.\nCulture and organization\nAs we deploy more models, its becoming clear that we will need to think beyond optimizing statistical and business metrics. While I havent touched on them during this short post, its clear that reliability and safety are going to be extremely important moving forward. How do you build and organize your team in a world where ML models have to take many other important things under consideration?\n\nFortunately there are members of our data community who have been thinking about these problems. The Future of Privacy Forum and Immuta recently released a report with some great suggestions on how one might approach machine learning projects with risk management in mind:\n\nWhen youre working on a machine learning project, you need to employ a mix of data engineers, data scientists, and domain experts.\nOne important change outlined in the report is the need for a set of data scientists who are independent from this model-building team. This team of validators can then be tasked with evaluating the ML model on things like explainability, privacy, and fairness.\n\nClosing remarks\nSo, what skills will be needed in a world where ML models are becoming mission critical? As noted above, fairness audits will require a mix of data and domain experts. In fact, a recent analysis of job postings from NBER found that compared with other data analysis skills, machine learning skills tend to be bundled with domain knowledge.\nBut youll also need to supplement your data and domain experts with with legal and security experts. Moving forward, well need to have legal, compliance, and security people working more closely with data scientists and data engineers.\n\nThis shouldnt come as a shock: we already invest in desktop security, web security, and mobile security. If machine learning is going to eat software, we will need to grapple with AI and ML security, too.\nRelated content:\n\nSharad Goel and Sam Corbett-Davies on Why its hard to design fair machine learning models\n\nAlon Kaufman on Machine learning on encrypted data\n\nChang Liu on How privacy-preserving techniques can lead to more robust machine learning models\n\nHow to build analytic products in an age when data privacy has become critical\nData collection and data markets in the age of privacy and machine learning\nWhat machine learning means for software development\nLessons learned turning machine learning models into real products and services\n\nContinue reading Managing risk in machine learning.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/kGQ1MxaWV5E/managing-risk-in-machine-learning", 
  "title": "Managing risk in machine learning"
 }, 
 {
  "content": "Gov Open Source, Bruce Sterling, Robot Science, and Illustrated TLS 1.3\n\nFDA MyStudies App -- open source from government, designed to facilitate the input of real-world data directly by patients which can be linked to electronic health data supporting traditional clinical trials, pragmatic trials, observational studies, and registries.\n\n\nBruce Sterling Interview -- on architecture, design, science fiction, futurism, and involuntary parks. (via Cory Doctorow)\n\nInventing New Materials with AI (MIT TR) -- using machine learning to generate hypotheses for new materials, to be explored and tested by actual humans.\n\nThe New Illustrated TLS Connection -- Every byte explained and reproduced. A revised edition in which we dissect the new manner of secure and authenticated data exchange, the TLS 1.3 cryptographic protocol.\n\n\nContinue reading Four short links: 12 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/3y7wrMtmOz8/four-short-links-12-november-2018", 
  "title": "Four short links: 12 November 2018"
 }, 
 {
  "content": "Counting Computers, New Software, Unix History, and Tencent Framework\n\nHow Many Computers Are In Your Computer? -- So, a desktop or smartphone can reasonably be expected to have anywhere from 15 to several thousand computers in the sense of a Turing-complete device which can be programmed and which is computationally powerful enough to run many programs from throughout computing history and which can be exploited by an adversary for surveillance, exfiltration, or attacks against the rest of the system. Which is why security folks sometimes sleep poorly at night.\n\nSome Notes on Running New Software in Production (Julia Evans) -- The playbook for understanding the software you run in production is pretty simple. Here it is: (1) Start using it in production in a non-critical capacity (by sending a small percentage of traffic to it, on a less critical service, etc); (2) Let that bake for a few weeks. (3) Run into problems. (4) Fix the problems. Go to step 3.\n\n\nUnix History (Rob Pike) -- know your past.\n\nOmi -- Tencent's ext generation web framework in 4KB JavaScript (Web Components + JSX + Proxy + Store + Path Updating).\n\n\nContinue reading Four short links: 9 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/A39O0de74gk/four-short-links-9-november-2018", 
  "title": "Four short links: 9 November 2018"
 }, 
 {
  "content": "The OReilly Data Show Podcast: Francesca Lazzeri and Jaya Mathew on digital transformation, culture and organization, and the team data science process.In this episode of the Data Show, I spoke with Francesca Lazzeri, an AI and machine learning scientist at Microsoft, and her colleague Jaya Mathew, a senior data scientist at Microsoft. We conducted a couple of surveys this yearHow Companies Are Putting AI to Work Through Deep Learning and The State of Machine Learning Adoption in the Enterpriseand we found that while many companies are still in the early stages of machine learning adoption, theres considerable interest in moving forward with projects in the near future. Lazzeri and Mathew spend a considerable amount of time interacting with companies that are beginning to use machine learning and have experiences that span many different industries and applications. I wanted to learn some of the processes and tools they use when they assist companies in beginning their machine learning journeys.Continue reading Lessons learned while helping enterprises adopt machine learning.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/OQyoJpygfVg/lessons-learned-while-helping-enterprises-adopt-machine-learning", 
  "title": "Lessons learned while helping enterprises adopt machine learning"
 }, 
 {
  "content": "Approximate Graph Pattern Mining, Ephemeral Containers, SaaS Metrics, and Edge Neural Networks\n\nASAP: Fast, Approximate, Graph Pattern Mining at Scale (Usenix) -- we present A Swift Approximate Pattern-miner (ASAP), a system that enables both fast and scalable pattern mining. ASAP is motivated by one key observation: in many pattern mining tasks, it is often not necessary to output the exact answer [...] an approximate count is good enough. (via Morning Paper)\n\nBinci -- tackling the same problem space as Docker Compose, but aimed at ephemeral containers rather than long-running ones (e.g., for test/CI systems).\n\nMetrics for Investors (Andrew Chen) -- detailed take on the metrics through which investors view SaaS businesses.\n\nHow to Fit Large Neural Networks on the Edge -- This blog explores a few techniques that can be used to fit neural networks in memory-constrained settings. Different techniques are used for the training and inference stages, and hence they are discussed separately.\n\n\nContinue reading Four short links: 8 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/vfCCybNgJZw/four-short-links-8-november-2018", 
  "title": "Four short links: 8 November 2018"
 }, 
 {
  "content": "Summarizing Text, Knowledge Database, AI Park, and Approximate Regexes\n\nFast Abstractive Summarization with Reinforce-Selected Sentence Rewriting -- Inspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary. We use a novel sentence-level policy gradient method to bridge the non-differentiable computation between these two neural networks in a hierarchical way, while maintaining language fluency. Source code available.\n\nKBPedia -- a comprehensive knowledge structure for promoting data interoperability and knowledge-based artificial intelligence, [which] combines seven \"core\" public knowledge basesWikipedia, Wikidata, schema.org, DBpedia, GeoNames, OpenCyc, and UMBELinto an integrated whole. Now has a serious open source offering.\n\nBaidu Opens AI Park in Beijing -- autonomous buses, smart walkways that track people's steps using facial recognition, intelligent pavilions equipped with the company's conversational DuerOS system, and augmented reality Tai Chi lessons. It's theatre, but theatre sets perceptions. In this case, the perception that China is miles ahead of America in AI. It was the AR Tai Chi that caught my eye.\n\nTRE: A Regex Engine with Approximate Matching -- It does this by calculating the Levenshtein distance (number of insertions, deletions, or substitutions it would take to make the strings equal) as it searches for a match.\n\n\nContinue reading Four short links: 7 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/GOBEjGwn2cA/four-short-links-7-november-2018", 
  "title": "Four short links: 7 November 2018"
 }, 
 {
  "content": "Get hands-on training in deep learning, Python, Kubernetes, blockchain, security, and many other topics.Learn new topics and refine your skills with 140 live online training courses we opened up for November, December, and January on our learning platform.\nArtificial intelligence and machine learning\nArtificial Intelligence for Big Data, November 28-29\nEssential Machine Learning and Exploratory Data Analysis with Python and Jupyter Notebook , December 3\nDeep Learning for Machine Vision, December 4\nBeginning Machine Learning with Scikit-Learn, December 5\nManaged Machine Learning Systems and Internet of Things, December 5-6\nNatural Language Processing (NLP) from Scratch, December 7\nMachine Learning in Practice, December 7\nDeep Learning with TensorFlow, December 12\nGetting Started with Machine Learning, December 12\nEssential Machine Learning and Exploratory Data Analysis with Python and Jupyter Notebook, January 7-8\nArtificial Intelligence: AI for Business, January 9\nManaged Machine Learning Systems and Internet of Things, January 9-10\nApplied Deep Learning for Coders with Apache MXNet, January 10-11\nArtificial Intelligence: An Overview of AI and Machine Learning, January 15\nHands-On Machine Learning with Python: Classification and Regression, January 16\nHands-On Machine Learning with Python: Clustering, Dimension Reduction, and Time Series Analysis, January 17\nBlockchain\nBuilding Smart Contracts on the Blockchain, November 29-30\nIntroducing Blockchain, December 7\nUnderstanding Hyperledger Fabric Blockchain, December 10-11\nBlockchain Applications and Smart Contracts: Developing Decentralized, December 13\nBusiness\nSpotlight on Innovation: The Future Beyond Digital, Entering a New Era of Exploration and Collaboration, November 28\nNegotiation Fundamentals, December 7\nApplying Critical Thinking, December 10\nHow to Give Great Presentations, December 10\nPerformance Goals for Growth, December 12\nLeadership Communication Skills for Managers, January 9\nIntroduction to Critical Thinking, January 10\nIntroduction to Delegation Skills, January 10\nWhy Smart Leaders Fail, January 15\nData science and data tools\nReal-Time Data Foundations: Kafka, December 3\nReal-Time Data Foundations: Spark, December 4\nGetting Started with Pandas, December 5\nGetting Started with Python 3, December 5-6\nMastering Pandas, December 6\nReal-Time Data Foundations: Flink, December 7\nApache Hadoop, Spark, and Big Data Foundations, December 10\nReal-Time Data Foundations: Time Series Architectures, December 10\nSentiment Analysis for Chatbots in Python, December 11\nHands-on Introduction to Apache Hadoop and Spark Programming, December 12-13\nBuilding Intelligent Bots in Python, December 13\nIntermediate Machine Learning with Scikit-Learn, December 17\nDesign\n3ds Max and V-Ray: The Path Towards Photorealism, December 14\nProgramming\nJava Full Throttle with Paul Deitel: A One-Day, Code-Intensive Java Standard Edition Presentation, November 15\nNext-Generation Java Testing with JUnit 5, November 15\nMastering the Basics of Relational SQL Querying, November 19-20\nDesigning Bots and Conversational Apps for Work, November 29\nPythonic Object-Oriented Programming, December 3\nBash Shell Scripting in 3 Hours, December 3\nBeyond Python Scripts: Logging, Modules, and Dependency Management, December 5\nLinux Filesystem Administration, December 5-6\nBeyond Python Scripts: Exceptions, Error Handling, and Command-Line Interfaces, December 6\nNext Level Git - Master your Workflow, December 6\nProgramming with Java 8 Lambdas and Streams, December 6\nConsumer Driven Contracts - A Hands-On Guide to Spring Cloud Contract, December 10\nSQL for Any IT Professional, December 10\nLinux Under the Hood, December 10\nLinux Troubleshooting, December 11\nScalable Concurrency with the Java Executor Framework, December 11\nNext Level Git - Master your Content, December 13\nLinux Performance Optimization, December 13\nMastering Go for UNIX Administrators, UNIX Developers, and Web Developers, December 13-14\nGetting Started with Java: From Core Concepts to Real Code in 4 Hours, December 17\nReactive Spring Boot, December 17\nScala Fundamentals: From Core Concepts to Real Code in 5 Hours, December 18\nProgramming with Data: Python and Pandas, December 18\nSpring Boot and Kotlin, December 18\nJulia 1.0 Essentials, December 18\nFunctional Design for Java 8, December 18-19\nJava 8 Generics in 3 Hours, December 20\nPython: The Next Level, January 7-8\nDesign Patterns Boot Camp, January 9-10\nLearning Python 3 by Example, January 10\nModern JavaScript, January 14\nLearn the Basics of Scala, January 14\nGetting Started with Pandas, January 14\nIntroduction to JavaScript Programming, January 14-15\nGetting Started with Python 3, January 14-15\nMastering Pandas, January 15\nScaling Python with Generators, January 15\nGetting Started with Pytest, January 16\nOCA Java SE 8 Programmer Certification Crash Course, January 16-18\nMastering Python's Pytest, January 17\nPythonic Design Patterns, January 18\nVisualization in Python with Matplotlib, January 18\nSecurity\nCybersecurity Offensive and Defensive Techniques in 3 Hours, December 7\nCyber Security Fundamentals, December 10-11\nCertified Ethical Hacker (CEH) Crash Course, December 13-14\nIntense Introduction to Hacking Web Applications, December 17\nCCNA Security Crash Course, December 18-19\nCompTIA PenTest+ Crash Course, December 18-19\nCompTIA Security+ SY0-501 Crash Course, January 7-8\nAWS Certified Security - Specialty Crash Course, January 7-8\nAWS Advanced Security with Config, GuardDuty, and Macie, January 14\nEthical Hacking Bootcamp with Hands-on Labs, January 15-17\nCompTIA Security+ SY0-501 Certification Practice Questions and Exam Strategies, January 16\nCyber Ops SECFND 210-250 Crash Course, January 16\nCCNA Cyber Ops SECOPS 210-255 Crash Course, January 18\nSoftware architecture\nDeveloping Incremental Architecture, December 10\nImplementing Evolutionary Architectures, December 13-14\nArchitecture for Continuous Delivery, December 17\nArchitecture by Example, December 17-18\nComparing Service-Based Architectures, December 18\nSoftware Architecture for Developers, January 7\nSystems engineering and operations\nAutomating with Ansible, December 3\nAn Introduction to DevOps with AWS, December 3\nRed Hat Certified Engineer (RHCE) Crash Course, December 4-7\n9 Steps to Awesome with Kubernetes, December 5\nAnsible for Managing Network Devices, December 5\nAmazon Web Services: AWS Managed Services, December 5-6\nNetwork Troubleshooting Using the Half Split and OODA, December 6\nGoogle Cloud Certified Associate Cloud Engineer Crash Course, December 6-7\nGetting Started with Continuous Delivery (CD), December 10\nAWS Monitoring Strategies, December 10\nPractical Docker, December 11\nGetting Started with Amazon Web Services (AWS), December 11-12\nAmazon Web Services: Architect Associate Certification - AWS Core Architecture Concepts, December 11-12\nCCNP R/S ROUTE (300-101) Crash Course, December 11-13\nAnsible in 3 Hours, December 12\nAmazon Web Services: AWS Design Fundamentals, December 13-14\nDeploying Container-Based Microservices on AWS, December 13-14\nKubernetes in 3 Hours, December 14\nJenkins 2: Up and Running, December 17\nCompTIA Cloud+ CV0-002 Exam Prep, December 17\nCCNP R/S SWITCH (300-115) Crash Course, December 17-19\nGoogle Cloud Platform (GCP) for AWS Professionals, December 18\nAWS CloudFormation Deep Dive, January 7-8\nRed Hat Certified System Administrator (RHCSA) Crash Course, January 7-10\nBuilding a Cloud Roadmap, January 9\nImplementing and Troubleshooting TCP/IP, January 9\nDocker: Up and Running, January 9-10\nBuilding Distributed Pipelines for Data Science Using Kafka, Spark, and Cassandra, January 9-11\nUnderstanding AWS Cloud Compute Options, January 10-11\nIstio on Kubernetes: Enter the Service Mesh, January 16\nAWS Certified SysOps Administrator (Associate) Crash Course, January 16-17\nChaos Engineering: Planning and Running Your First Game Day, January 17\nVisualizing Software Architecture with the C4 Model, January 18\nWeb programming\nHands-On Chatbot and Conversational UI Development, December 3-4\nBuilding APIs with Django REST Framework, December 17\nDeveloping Web Apps with Angular and TypeScript, December 17-19\nRethinking REST: A Hands-On Guide to GraphQL and Queryable APIs, December 18\nContinue reading 140 live online training courses opened for November, December, and January.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/a4BMrDOvcgM/140-live-online-training-courses-opened-for-november-december-and-january", 
  "title": "140 live online training courses opened for November, December, and January"
 }, 
 {
  "content": "Understanding how the Kubernetes scheduler makes scheduling decisions is critical to ensure consistent performance and optimal resource utilization.Kubernetes is an industry-changing technology that allows massive scale and simplicity for the orchestration of containers. Most of us happily push thousands of deployments and pods to Kubernetes every day. Have you ever wondered what sorcery is at play in Kubernetes to determine where all those pods will be created in the Kubernetes cluster? All of this is made possible by the kube-scheduler.\nUnderstanding how the Kubernetes scheduler makes scheduling decisions is critical in order to ensure consistent performance and optimal resource utilization. All scheduling in Kubernetes is done based upon a few key pieces of information. First, it is using information about the worker node to determine what the total capacity of the node is. Using kubectl describe node ", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Cb1KgIHWqaY/kubernetes-scheduling-magic-revealed", 
  "title": "Kubernetes' scheduling magic revealed"
 }, 
 {
  "content": "People Don't Change, Open Access, Event Database, and Apple Maps\n\nPeople Don't Change -- interesting and entertaining talk to remind you that modern people with their selfies and mobile phone obsessions aren't new special creatures unlike the people of the past. The first half is non-technical similarities, and the second half kicks into how the same human drives behind our tech obsessions can be found (with different tech) in the past. (via Daniel Siegel)\n\nBill and Melinda Gates Foundation Endorses European Open-Access Plan (Nature) -- the Wellcome Trust, which funds over a billion pounds of research each year, will only permit publication in subscription journals if there's simultaneous release in PubMed Central. The Gates Foundation, which is already strongly pro-OA, is bringing its requirements in line with the new European Plan S. (via Slashdot)\n\nEventStore -- open source, functional database with complex event processing in JavaScript.\n\n\nApple's New Maps -- fantastically detailed write-up of the new Apple Maps, coverage, visuals, omissions.\n\nContinue reading Four short links: 6 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/sHB1E77bcMg/four-short-links-6-november-2018", 
  "title": "Four short links: 6 November 2018"
 }, 
 {
  "content": "Probabilistic Model Checker, Notebooks to Docs, AWS 12-Factor Apps, and AI Physicist\n\nStormchecker -- A modern model checker for probabilistic systems. Test your models of your distributed system.\n\nMonoCorpus -- a note-taking app for software and machine learning engineers meant to encourage learning, sharing, and easier development. Increase documentation for yourself and your team without slowing your velocity. Take notes as part of your process instead of dedicating time to writing them. An interesting use for notebooks.\n\nOdin -- Deploy your 12-factor-applications to AWS easily and securely with the Odin, an AWS Step Function based on the step framework that deploys services as auto-scaling groups (ASGs).\n\n\nToward an AI Physicist for Unsupervised Learning -- We investigate opportunities and challenges for improving unsupervised machine learning using four common strategies with a long history in physics: divide-and-conquer, Occam's Razor, unification, and lifelong learning. Instead of using one model to learn everything, we propose a novel paradigm centered around the learning and manipulation of *theories*, which parsimoniously predict both aspects of the future (from past observations) and the domain in which these predictions are accurate. (see also MIT TR)\n\nContinue reading Four short links: 5 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/DPXjQnXNh0w/four-short-links-5-november-2018", 
  "title": "Four short links: 5 November 2018"
 }, 
 {
  "content": "Kris Nova looks at the new era of the cloud native space and the kernel that has made it all possible: Kubernetes.Continue reading The freedom of Kubernetes.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/EZHoXzmrb6Q/the-freedom-of-kubernetes", 
  "title": "The freedom of Kubernetes"
 }, 
 {
  "content": "Claire Janisch looks at some of the best biomimicry opportunities inspired by natures software and wetware.Continue reading Learning from the web of life.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/XBiSWP8Hn6s/learning-from-the-web-of-life", 
  "title": "Learning from the web of life"
 }, 
 {
  "content": "Martin Kleppmann shows how recent computer science research is helping develop the abstractions and APIs for the next generation of applications.Continue reading What changes when we go offline-first?.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/EEGxTInS3TY/what-changes-when-we-go-offline-first", 
  "title": "What changes when we go offline-first?"
 }, 
 {
  "content": "Jane Adams examines the ways data-driven recruiting fails to achieve intended results and perpetuates discriminatory hiring practices.Continue reading The misinformation age.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/q_tehzT4ww8/the-misinformation-age", 
  "title": "The misinformation age"
 }, 
 {
  "content": "Colorizing Photos, Evolving Space Invaders, Is It Too Late?, and Decision-Making\n\nDeOldify -- Deep learning-based project for colorizing and restoring old images. Impressive, and open source.\n\nInvaderZ -- Space invaders, but the invaders evolve with a genetic algorithm.\n\n\nThe Best Way to Predict the Future is to Create It. But Is It Already Too Late? -- Alan Kay lecture. If we've done things with technology that got us in a bit of a pickle, doing things with technology will probably only make that worse. When Alan Kay speaks, I listen.\n\nFarsighted -- new book by Steven Johnson, on powerful tools for honing the important skill of complex decision-making. Shades of Algorithms to Live By, but Johnson is a good writer and a good thinker, so this promises to be much more.\n\nContinue reading Four short links: 2 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/VNmhLb76cNE/four-short-links-2-november-2018", 
  "title": "Four short links: 2 November 2018"
 }, 
 {
  "content": "Omoju Miller outlines a vision where we harness human action for a better future.Continue reading A new vision for the global brain: Deep learning with people instead of machines.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/dfvYpqN17N8/a-new-vision-for-the-global-brain-deep-learning-with-people-instead-of-machines", 
  "title": "A new vision for the global brain: Deep learning with people instead of machines"
 }, 
 {
  "content": "Anne Currie says excessive and dirty energy use in data centers is one of the biggest ethical issues facing the tech industry.Continue reading Kubernetes: Good or evil? The ethics of data centers.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/WmalftzWNIg/kubernetes-good-or-evil-the-ethics-of-data-centers", 
  "title": "Kubernetes: Good or evil? The ethics of data centers"
 }, 
 {
  "content": "Watch highlights from expert talks covering Kubernetes, chaos engineering, deep learning, and more. \nPeople from across the distributed systems world came together in London for the O'Reilly Velocity Conference. Below you'll find links to highlights from the event.\nKubernetes: Good or evil? The ethics of data centers\nAnne Currie says excessive and dirty energy use in data centers is one of the biggest ethical issues facing the tech industry.\n\nWatch \"Kubernetes: Good or evil? The ethics of data centers.\"\n\nIncognito mentorship\nKatrina Owen says the valuable skills that experienced professionals lack are at the vital margins of their careers.\n\nWatch \"Incognito mentorship.\"\n\nDeriving meaning in a time of chaos: The intersection between chaos engineering and observability\nCrystal Hirschorn discusses how organizations can benefit from combining established tech practices with incident planning, post-mortem-driven development, chaos engineering, and observability.\n\nWatch \"Deriving meaning in a time of chaos: The intersection between chaos engineering and observability.\"\n\nA new vision for the global brain: Deep learning with people instead of machines\nOmoju Miller outlines a vision where we harness human action for a better future.\n\nWatch \"A new vision for the global brain: Deep learning with people instead of machines.\"\n\nLearning from the web of life\nClaire Janisch looks at some of the best biomimicry opportunities inspired by natures software and wetware.\n\nWatch \"Learning from the web of life.\"\n\nThe misinformation age\nJane Adams examines the ways data-driven recruiting fails to achieve intended results and perpetuates discriminatory hiring practices.\n\nWatch \"The misinformation age.\"\n\nThe freedom of Kubernetes\nKris Nova looks at the new era of the cloud native space and the kernel that has made it all possible: Kubernetes.\n\nWatch \"The freedom of Kubernetes.\"\n\nWhat changes when we go offline first?\nMartin Kleppmann shows how recent computer science research is helping develop the abstractions and APIs for the next generation of applications.\n\nWatch \"What changes when we go offline first?\"\n\nContinue reading Highlights from the O'Reilly Velocity Conference in London 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/gInhya0ZRqw/highlights-from-velocity-uk-2018", 
  "title": "Highlights from the O'Reilly Velocity Conference in London 2018"
 }, 
 {
  "content": "Crystal Hirschorn discusses how organizations can benefit from combining established tech practices with incident planning, post-mortem-driven development, chaos engineering, and observability.Continue reading Deriving meaning in a time of chaos: The intersection between chaos engineering and observability.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/T_9uISDNDwA/deriving-meaning-in-a-time-of-chaos", 
  "title": "Deriving meaning in a time of chaos: The intersection between chaos engineering and observability"
 }, 
 {
  "content": "Katrina Owen says the valuable skills that experienced professionals lack are at the vital margins of their careers.Continue reading Incognito mentorship.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/MOL2NIzjfgk/incognito-membership", 
  "title": "Incognito mentorship"
 }, 
 {
  "content": "Data Science, AI Ethics, Coded for Curiosity, and Worm Parking\n\nHow to Decide Which Data Science Projects to Pursue (Hilary Mason) -- data science projects are not independent from one another. With each completed project, successful or not, you create a foundation to build later projects more easily and at lower cost. Some good advice on how to build a non-sucky data strategy.\n\nAI Ethics, Impossibility Theorems, and Tradeoffs -- There is no policy choice that satisfies all ethical principles. A data scientist takes us through the options and the math that makes this statement true.\n\nReinforcement Learning with Prediction-Based Rewards (Open AI) -- Weve developed random network distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on Montezumas Revenge. RND achieves state-of-the-art performance, periodically finds all 24 rooms, and solves the first level without using demonstrations or having access to the underlying state of the game.\n\n\nC. Elegans Can Park a Car -- it only took 12 neurons, and yet you look down any city street and...*sigh*.\n\nContinue reading Four short links: 1 November 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/9IkOb4nW5xg/four-short-links-1-november-2018", 
  "title": "Four short links: 1 November 2018"
 }, 
 {
  "content": "Who Gets What, Kindle Notes, Advertising in Young Children's Apps, and Hidden Data\n\nRethinking Who Gets What and Why -- Tim O'Reilly's latest talk. Read the presenter notes for the meat.\n\nKlipbook -- convert highlights and notes on your Kindle to nice HTML, Markdown, or JSON.\n\n\nAdvertising in Young Children's Apps: A Content Analysis -- Of the 135 apps reviewed, 129 (95%) contained at least one type of advertising. These included use of commercial characters (42%); full-app teasers (46%); advertising videos interrupting play (e.g., pop-ups [35%] or to unlock play items [16%]); in-app purchases (30%); prompts to rate the app (28%) or share on social media (14%); distracting ads such as banners across the screen (17%) or hidden ads with misleading symbols such as $ or camouflaged as gameplay items (7%). Advertising was significantly more prevalent in free apps (100% vs 88% of paid apps), but occurred at similar rates in apps labeled as educational versus other categories. Many things happening online that were prohibited for children's TV in the 1970s. (via BoingBoing)\n\nJPG with a ZIP (Twitter) -- the image in this tweet is also a valid ZIP archive, containing a multipart RAR archive, containing the complete works of Shakespeare.\n\n\nContinue reading Four short links: 31 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/DFupIlme5M8/four-short-links-31-october-2018", 
  "title": "Four short links: 31 October 2018"
 }, 
 {
  "content": "Stefan Tilkov looks at common software architecture pitfalls and explains how they can be avoided.Continue reading Why software architects fail and what to do about it.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Iv3IfWLcOts/why-software-architects-fail-and-what-to-do-about-it", 
  "title": "Why software architects fail and what to do about it"
 }, 
 {
  "content": "Trisha Gee shares advice and lessons she learned the hard way while managing her career as a developer, lead, and technical advocate.Continue reading Career advice for architects.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/mNwm2glY7vw/career-advice-for-architects", 
  "title": "Career advice for architects"
 }, 
 {
  "content": "Mike Roberts explores ideas for trying serverless as well as a framework for evaluating its effectiveness within your organization.Continue reading Introducing serverless to your organization.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/giHGJUcCARc/introducing-serverless-to-your-organization", 
  "title": "Introducing serverless to your organization"
 }, 
 {
  "content": "AI Animations, Dataflow Apps, Decensoring with AI, and FPGA Programming\n\nA Mixed-Initiative Interface for Animating Static Pictures -- this looks awesome!\n\nNoria: Dynamic, Partially-Stateful Dataflow for High-Performance Web Applications -- Noria makes intelligent use of dataflow beneath the SQL interface (i.e., dataflow is not exposed as an end-user programming model) in order to maintain a set of (semi-)materialized views. Noria itself figures out the most efficient dataflows to maintain those views, and how to update the dataflow graphs in the face of schema / query set changes.\n\n\nDeCensoring Hentai with Deep Learning -- I already don't like where AI has taken us, and we're nowhere near SkyNet yet.\n\nSpatial -- a high-level programming language for FPGAs.\n\n\nContinue reading Four short links: 30 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/7FVKfIgFsAc/four-short-links-30-october-2018", 
  "title": "Four short links: 30 October 2018"
 }, 
 {
  "content": "Sarah Wells explains how the Financial Times migrated microservices between container stacks without affecting production users.Continue reading The challenges of migrating 150+ microservices to Kubernetes.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/3CMB8_N_OGA/the-challenges-of-migrating-150-microservices-to-kubernetes", 
  "title": "The challenges of migrating 150+ microservices to Kubernetes"
 }, 
 {
  "content": "Watch highlights from expert talks covering microservices, Kubernetes, serverless, and more. People from across the software architecture world came together in London for the O'Reilly Software Architecture Conference. Below you'll find links to highlights from the event.\nThe challenges of migrating 150+ microservices to Kubernetes\nSarah Wells explains how the Financial Times migrated microservices between container stacks without affecting production users.\n\nWatch \"The challenges of migrating 150+ microservices to Kubernetes.\"\n\nAre microservices a security threat?\nLiz Rice outlines the security implications of microservices, containers, and serverless.\n\nWatch \"Are microservices a security threat?\"\n\nPotholes in the road from monolithic hell: Microservices adoption anti-patterns\nChris Richardson describes microservices anti-patterns hes observed while working with clients around the world.\n\nWatch \"Potholes in the road from monolithic hell: Microservices adoption anti-patterns.\"\n\nWhy software architects fail and what to do about it\nStefan Tilkov looks at common software architecture pitfalls and explains how they can be avoided.\n\nWatch \"Why software architects fail and what to do about it.\"\n\nIntroducing serverless to your organization\nMike Roberts explores ideas for trying serverless as well as a framework for evaluating its effectiveness within your organization.\n\nWatch \"Introducing serverless to your organization.\"\n\nCareer advice for architects\nTrisha Gee shares advice and lessons she learned the hard way while managing her career as a developer, lead, and technical advocate.\n\nWatch \"Career advice for architects.\"\n\nContinue reading Highlights from the O'Reilly Software Architecture Conference in London 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/B3QfonV8W_c/highlights-from-software-architecture-uk-2018", 
  "title": "Highlights from the O'Reilly Software Architecture Conference in London 2018"
 }, 
 {
  "content": "Liz Rice outlines the security implications of microservices, containers, and serverless.Continue reading Are microservices a security threat?.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/8FeCg0FentA/are-microservices-a-security-threat", 
  "title": "Are microservices a security threat?"
 }, 
 {
  "content": "Chris Richardson describes microservices anti-patterns hes observed while working with clients around the world.Continue reading Potholes in the road from monolithic hell: Microservices adoption anti-patterns.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/O4_zbVCL9Sg/potholes-in-the-road-from-monolithic-hell-microservices-adoption-anti-patterns", 
  "title": "Potholes in the road from monolithic hell: Microservices adoption anti-patterns"
 }, 
 {
  "content": "Quantum Internet, Live Coding, Ethics Checklists, and Robot Compendium\n\nQuantum Internet: A Vision for the Road Ahead (Science) -- interesting paper laying out a roadmap for development of \"the quantum internet.\" Stages: trusted repeater networks, prepare and measure networks, entanglement distribution networks, quantum memory networks, fault-tolerant few-qubit networks, and quantum computing networks. The full paper is behind a paywall (or sci-hub).\n\nAlgojammer -- neat prototype of a Bret-Victor-like system to help you develop and understand algorithms. The execution of your code should be thought of as just a physical fact about the lines of text you have written. In the same way we might consider the \"number of 'e' characters\" in the code, or the \"average line length\" of the code, the \"execution\" of the code is just a static fact that is entirely determined by the code.\n\n\nData Science Ethics Checklists -- This is not meant to be the only ethical checklist, but instead we try to capture reasonable defaults that are general enough to be widely useful. For your own projects with particular concerns, we recommend your own checklist.yml file that is maintained by your team and passed to this tool with the -l flag.\n\n\nIEEE Robots Guide -- a compendium of robots that are real and here today, most of which you can buy, from hands to scuttlers to humanoid robots with Einstein heads, to something that looks like a little yellow bird.\n\nContinue reading Four short links: 29 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/cJHNr4f62Lc/four-short-links-29-october-2018", 
  "title": "Four short links: 29 October 2018"
 }, 
 {
  "content": "Legit DRM Hacking, CPU Emulation, Phish Yourself, and Data Structures\n\nFeds Say Hacking DRM to Fix Your Electronics Is Legal -- The Librarian of Congress and U.S. Copyright Office just proposed new rules that will give consumers and independent repair experts wide latitude to legally hack embedded software on their devices in order to repair or maintain them. This exemption to copyright law will apply to smartphones, tractors, cars, smart home appliances, and many other devices. (via BoingBoing)\n\nUnicorn Engine -- a lightweight multi-platform, multi-architecture CPU emulator framework.\n\n\nGophish -- an open source phishing toolkit designed for businesses and penetration testers. It provides the ability to quickly and easily set up and execute phishing engagements and security awareness training.\n\n\nThe Periodic Table of Data Structures -- We show that it is possible to argue about the design space of data structures. By discovering the first principles of the design of data structures and putting them in a universal model, we study their combinations and their impact on performance. We show that it is possible to accelerate research and decision-making concerning data structure design, hardware, and workload by being able to quickly compute the performance impact of a vast number of designs; several orders of magnitude more designs than what has been published during the last six decades.\n\n\nContinue reading Four short links: 26 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/8IUddYbGN08/four-short-links-26-october-2018", 
  "title": "Four short links: 26 October 2018"
 }, 
 {
  "content": "The OReilly Data Show Podcast: Alon Kaufman on the interplay between machine learning, encryption, and security.In this episode of the Data Show, I spoke with Alon Kaufman, CEO and co-founder of Duality Technologies, a startup building tools that will allow companies to apply analytics and machine learning to encrypted data. In a recent talk, I described the importance of data, various methods for estimating the value of data, and emerging tools for incentivizing data sharing across organizations. As I noted, the main motivation for improving data liquidity is the growing importance of machine learning. Were all familiar with the importance of data security and privacy, but probably not as many people are aware of the emerging set of tools at the intersection of machine learning and security. Kaufman and his stellar roster of co-founders are doing some of the most interesting work in this area. Continue reading Machine learning on encrypted data.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/ILhPz45dOxM/machine-learning-on-encrypted-data", 
  "title": "Machine learning on encrypted data"
 }, 
 {
  "content": "As lists are the raw material of strategy and technology architecture, MECE list-making is one of the most useful tools you can have in your tool box.\nMECE, pronounced \"mee-see,\" is a tool created by the leading business strategy firm McKinsey. It stands for \"mutually exclusive, collectively exhaustive,\" and dictates the relation of the content, but not the format, of your lists. Because of the vital importance of lists, this is one of the most useful tools you can have in your tool box.\nThe single most important thing you can do to improve your chances of making a winning technology is to become quite good at making lists.\nLists are the raw material of strategy and technology architecture. They are the building blocks, the lifeblood. They are the foundation of your strategy work. And they are everywhere. Therefore, if they are weak, your strategy will crumble. You can be a strong technologist, have a good idea, and care about it passionately. But if you arent practically perfect at list-making, your strategy will flounder and your efforts will fail.\nThats because everything you do as you create your technology strategy starts its life as a list, and then blossoms into something else. Your strategy is, at heart, a list of lists. Thinking of your work from this perspective is maybe the best trick to creating a sane, organized, productive context for your work. Let's talk about lists for a moment.\nThere are two parts to a practically perfect list: it must be conceived properly, and it must be MECE, which we will define in a moment.\nIn a properly conceived list, two things are crystal clear:\n\n\nWho the audience is\n\n\nWhy they care\n\n\nYou can determine who your audience is by asking the following key questions:\n\n\nUpon reading this list, can the audience make a decision they could not make before having the information in the list?\n\n\nUpon reading the list, can the audience now go do something they could not have known to do before?\n\n\nThese are the two reasons to bother creating any kind of information in a strategy. In this context, there is little point, time, or patience for a document that merely helps a general audience understand something. Your lists must be lean. That means making them directive toward work that someone will go and do, or providing the data that allows a decision-maker to decide the best course of action. The RACI (responsible, accountable, consulted, and informed) chart is a list. It answers the question for the project team of who is assigned to what role so that everyone knows who is in charge of what, who is the decision-maker for what, and who is doing the work, and if someone sees his name on the list with an \"R\" by an item, he can go do that work. The stakeholder list is primarily for the project manager. It lets him decide whom to include in what meetings and whom to contact for certain questions. But if these, and all the many other lists you create as part of your technology strategy, are not MECE, your building blocks will be weak and your strategic efforts will crumble. Let's look at some examples to make this clear.\nThis formula is MECE:\n\nOpportunity Cost = Return of Most Lucrative Option  Return of Chosen Option\n\nThis formula is MECE:\n\nProfit = Revenue  Cost\n\nRevenue  Cost = Profit is MECE. That's because together those three items make a complete thought, divide across lines that don't overlap, and nothing is left out. All of the parts of the money are accounted for within the same level of discourse. It is nonsense to leave out \"Revenue\" and simply state \" Cost = Profit.\" There are only two ways to increase profit: increase revenue or decrease costs. Recognizing the formula as MECE can help remind you to address both the cost and the revenue aspects in your strategy.\nThis list is MECE:\n\nSpades, Diamonds, Hearts, Clubs\n\nThis list is MECE:\n\nWinter, Spring, Summer, Fall\n\nEach entry in the list is mutually exclusive of every other one. There is no overlap in their content. Winter ends on a specific day of the year, and then the next day is the start of spring. Every date on the calendar is, with certainty, part of one and only one season. There is no card in the deck that is part Spades and part Diamonds.\nThe elements in the list, when taken together as a collection, entirely define the category. No item is left out, leaving an incomplete definition. Thus, the list is collectively exhaustive.\nThis is not MECE:\n\nNorth, South, West\n\nIt's not collectively exhaustive. It fails to include East, and is therefore an improperly structured list.\nConsider the following list:\n\nRevenue  Cost = Profit. Free Cash Flow.\n\nThis is not MECE because \"free cash flow\" is not at the same level of discourse as the other items. It is true that free cash flow is an important part of any public company's earnings statements. But that is unrelated to this equation, even though they appear to all be in the category of \"stuff about money in a company.\" That's a weak category for a list because it's not sufficiently directed to an audience for a goal.\nWhat about this one:\n\nInternal Stakeholders, External Stakeholders, Development Teams\n\nThis isn't MECE because \"internal\" and \"external\" divide the world between them. Development teams are a subcategory of internal stakeholders for a technology strategy.\nElements that are subcategories of other elements must not be included. Consider this list:\n\nNorth, South, Southwest, East\n\nThis is not MECE because it leaves out one of the elements, West, and so is not collectively exhaustive. It also includes Southwest, which is not topologically on the same plane as the other elements. It dips into a lower level of distinction, as in the \"free cash flow\" example. Southwest is contained within the higher level of abstraction of South. So, the elements on this list are not mutually exclusive.\nThese examples are straightforward (obvious) in order to illustrate the point. But they share an attribute that precious few lists in the world have: they are enums by definition. It is clear what goes on the list and what doesnt. Most things in life are not this simple.\nConsider the following list of departments or job roles in a dev shop:\n\nSoftware Developers\nArchitects\nAnalysts\n\nIt's not exhaustive: we left out testers, and other roles depending on your organization, such as release engineers, database administrators, project managers, and so on. To test if our list is MECE, we must ensure we have pushed ourselves to think of all the relevant components that make up that category.\nRemember the first rule: know your audience. Your longer, more detailed lists should be kept for your private analysis to help you reach your conclusion, or reserved for lists of things to be done in the project, such as a work breakdown structure. But you don't want long lists when working with executives because they have executive ADD. Even though you'll worry that you're leaving out crucial things, just give them the summary, but make it MECE. Then you can reveal only the headline: the impactful conclusion that makes a difference to your audience.\n\nThe Rule of Three\nA good rule of thumb is to find the level of abstraction that keeps your lists in categories of three or five items. For whatever reason, people seem to more naturally understand and remember lists of three, or at the least, odd-numbered lists. Consider two movie titles: The Good, The Bad, and The Ugly is more memorable than The Cook, The Thief, His Wife, and Her Lover. Push yourself to make your lists with three to five items. Prefer lists of three or five over lists of four. You'll find this little trick helps keep your thinking quick and nimble, and it will shorten your turnaround time because your work will be closer to what youll need to present to executives and stakeholders.\n\nConsider this list of age groups:\n\n05\n610\n1115\n1625\n2635\n3645\n4654\n5565\n6675\n76 and above\n\nThis list is technically MECE. None of the categories overlap, and the sum of the subcategories equals the whole category. It might be OK for a data scientist doing customer segmentation. But probably not even then. Its too fine-grained and low-level, so its not very good for strategy work. You need to keep your visor higher; look more broadly to horizons to distill the few things that really make an impact and drive change. Its more analysis and art than science. So, even though the list is technically correct, you will lose your audience with details like this, and you can find ways to cluster and consolidate them better, along the contours of a real difference or divergence, depending on your own organizations products, services, and markets.\nLet's look at a quick example of how to apply this idea of MECE lists.\n\nApplying MECE Lists\nImagine you've been enlisted to create a recommendation to the CTO for a new database system to replace your legacy system. If you merely state the single database system you want to buy, any responsible executive will reject your recommendation as heavily biased, poorly considered, and potentially reckless.\nSo, we want to first consider our audience, with empathy, and always ask: who is this for, and what do they need to know either to make a decision or to do the thing in question?\nYour deciding audience wants to know they have been given a clear, thorough, thoughtful, unbiased proposal and that they are not being manipulated. In our empathy, we realize everyone has a boss, and that no one in a company of any size just makes a decision in a vacuum. It's not the CTO's money. So your CTO must in turn answer to his bosses for the system he selects, and is accountable for its success. Your recommendation will be successful if you give your deciding audience a list of MECE lists.\nBut the list of database system choices is potentially in the thousands. It is impossible to include all of them, and impractical and unhelpful to include even 20 of them. Being ridiculous is not what is meant by \"collectively exhaustive.\" So, first we'll create a list of criteria to help us make our final list MECE. Include three or five factors on which you will base your selection and write those down, as they become part of your recommendation, too. Youre showing your audience how you came to your conclusion, just like showing the long math in school: youre not just giving the answer, but providing the steps by which you arrived at it. This helps the audience follow your story and agree with your conclusion.\nThen we'll perform a survey of the landscape, including systems that meet the criteria. Include open source alternatives as well as commercial vendors. We might have a few of each. If we recommended only the one we already wanted, we would miss the chance to perform the analysis, squander an opportunity for learning that might change or augment our view, and lose confidence in our choice and ability to execute. Including only our one recommendation would certainly and immediately invite considerable skepticism and questioning about the alternatives and how we considered them.\nSo make a MECE list of options. The list is exhaustive according to your chosen criteria. Say you have 8 or 10 options in your list of all the database systems considered. Say so in your recommendation. It shows youve done your homework and suggests less bias and a more data-driven, analytical approach. Then say you narrowed it down to five options to present. That list includes two you reject and state why. You have a list of three options remaining.\nFor each element on your list of remaining recommended vendors, create another list of lists: \"advantages, disadvantages\" (that's a MECE list itself). The elements in each list should be something about the technology, particularly: 1) the functional requirements such as key features that distinguish it from the competition, and 2) nonfunctional requirements such as performance, availability, security, and maintainability (that's a MECE list, too). Consider these systems also from the business perspective: ability to train the staff, popularity/access to future staff, ease of use, and so forth.\nThen from the list of acceptible candidates, present them all, ranked as good, better, and best. (The good, better, best list is MECE too, because you wouldn't improve its MECE-ness by adding a \"horrible\" option: the category or name of this list is the acceptable options, which presumably does not include \"horrible,\" and therefore unusable ones.\")\nThe good option might be the one that is acceptable to you, and is low cost but not optimal. The best one might be the most desirable but highest cost, and so on.\nOrganizing your list this way makes an executive feel more confident that you have an understanding of the entire landscape, arent too biased, and show your reasoning. That makes your recommendation stronger.\n\nThe Celesital Emporium...\nIn 1668, English philosopher John Wilkins published a proposal for adopting a universal language as well as a universal system of measurements. In his estimation, this was an entirely rational classification system.\nIn 1952, Argentine poet Jorge Louis Borges published an essay titled \"The Analytical Language of John Wilkins.\" As a critique of Wilkins's work, Borges offered the following list, in his story \"The Celestial Emporium of Benevolent Knowledge,\" purported to have been created by a 14th-century Chinese emperor as his taxonomy for classifying the members of the animal kingdom:\n\nThose that belong to the emperor\nEmbalmed ones\nThose that are trained\nSuckling pigs\nMermaids (or sirens)\nFabulous ones\nStray dogs\nThose that are included in this classification\nThose that tremble as if they were mad\nInnumerable ones\nThose drawn with a very fine camel hair brush\nEt cetera\nThose that have just broken the flower vase\nThose that, at a distance, resemble flies\n\nThe list is hilarious because it is so obviously an example of an incomplete set of sets. There's a lot left out here. Many of the categories also overlap (can a creature not be at once \"fabulous\" and belong to the emperor and have just broken the flower vase?). Do not all animals, at a sufficient distance, resemble flies? What belongs in \"Et cetera\"? Who could possibly make meaningful use of this?\nBorges's point was that there is not a single, unifying, rational way to classify All The Things, that there are cultural differences that affect our views, and that ultimately such taxonomies can be shown to be arbitrary. So that's understood. The point here is that the division of animals in the \"Celestial Emporium of Benevolent Knowledge\" is perhaps the least-MECE list in the history of earth. Yet, how many of our project and architecture lists, on further inspection, perhaps resemble it?\n\nGetting good at quickly checking if you are thinking in lists and then making sure they're MECE has the pleasant side effect of helping build your powers of analysis. Think of MECE as a lens. Every time you make a list, immediately test if it is MECE. Use it as a heuristic device with your team: inspect your list with the team as youre meeting, be sure to ask if the current list youre working on is MECE, and then refine it. Your team may groan at first, but they will gradually start to see the value, and then they will not be able to imagine how they ever lived without it.\nMake your work lists of lists, and make those lists MECE. Your recommendations have a better chance of getting accepted, supported, and executed upon. And you will create more power for your organization and your team.\n\n\nContinue reading A foundational strategy pattern for analysis: MECE.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/h1ERwZ4YAjQ/a-foundational-strategy-pattern-for-analysis-mece", 
  "title": "A foundational strategy pattern for analysis: MECE"
 }, 
 {
  "content": "Winners Take All, Fairness, Simultaneous Translation, Secure GPUs\n\nWinners Take All: The Elite Charade of Changing the World (YouTube) -- talk at Google (!) by Anand Giridharadas, author of a book of the same name. What a great talk.\n\nFairness and Abstraction in Sociological Systems -- Bedrock concepts in computer science such as abstraction and modular design are used to define notions of fairness and discrimination, to produce fairness-aware learning algorithms, and to intervene at different stages of a decision-making pipeline to produce \"fair\" outcomes. In this paper, however, we contend that these concepts render technical interventions ineffective, inaccurate, and sometimes dangerously misguided when they enter the societal context that surrounds decision-making systems. We outline this mismatch with five \"traps\" that fair-ML work can fall into even as it attempts to be more context-aware in comparison with traditional data science. Noted researcher (and Friend Of O'Reilly) danah boyd is a co-author.\n\nBaidu Simultaneous Translation -- audio to text, Chinese to English. Bring on the Babelfish!\n\nGraviton: Trusted Execution Environments on GPUs -- Graviton enables applications to offload security- and performance-sensitive kernels and data to a GPU, and execute kernels in isolation from other code running on the GPU and all software on the host, including the device driver, the operating system, and the hypervisor.\n\n\nContinue reading Four short links: 25 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/u7GuQKp7Yas/four-short-links-25-october-2018", 
  "title": "Four short links: 25 October 2018"
 }, 
 {
  "content": "Good Modeling, Real-Time Command Line, Data Structure Synthesis, and Free the Law\n\nAbout Our Model -- high school stats class makes a model for election prediction and lists all their assumptions. A good role model for the rest of us.\n\nUltimate Plumber -- a tool for writing Linux pipes in a terminal-based UI interactively, with instant live preview of command results. Real-time feedback changes the command line.\n\nGeneralized Data Structure Synthesis -- This paper shows how to synthesize data structures that track subsets and aggregations of multiple related collections. Our technique decomposes the synthesis task into alternating steps of query synthesis and incrementalization. [...] As an added benefit of this approach over previous work, the synthesized data structure is optimized for not only the queries in the specification but also the required update operations. I love tools that automate or expedite programming.\n\nAppeals Court to Georgia: Code Can't Be Copyrighted (EFF) -- On Friday, the U.S. Court of Appeals for the 11th Circuit handed down a powerful opinion that struck down the state of Georgias attempt to use copyright to suppress publication of its own laws. The ruling, which gives Georgians the right to read and publish the Official Code of Georgia Annotated, or OCGA, may also improve public access to legislative documents in other states. Georgia claimed copyright on their own laws and charged citizens to read them, bringing suit against Public Resource for publishing those laws for free.\n\nContinue reading Four short links: 24 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/kw12JZHGXYE/four-short-links-24-october-2018", 
  "title": "Four short links: 24 October 2018"
 }, 
 {
  "content": "Forecasting, Cars and Privacy, Quantum Communications, and Positive Communications\n\nForecasting at Uber: An Introduction -- Actually, classical and ML methods are not that different from each other, but distinguished by whether the models are more simple and interpretable or more complex and flexible. In practice, classical statistical algorithms tend to be much quicker and easier-to-use. An important message that isn't getting as much airplay as the sales pitches: deep learning is unfairly good on some problems, but not all.\n\nThe Next Data Minefield Is Your Car -- GM captured minuted details such as station selection, volume level, and ZIP codes of vehicle owners, and then used the cars built-in Wi-Fi signal to upload the data to its servers. The goal was to determine the relationship between what drivers listen to and what they buy and then turn around and sell the data to advertisers and radio operators. And it got really specific: GM tracked a driver listening to country music who stopped at a Tim Hortons restaurant. (No data on that donut order, though.)\n\n\nInside Europe's Quest for an Unhackable Quantum Internet (MIT TR) -- China has also built a land-based QKD communications network from Beijing to Shanghai that banks and other companies are using to transmit sensitive commercial data. China's approach requires trusted quantum-classical-quantum repeaters every 10km, whereas the Dutch university at the center of this article is looking to use quantum teleportation. Interesting to see the Dutch are connecting universities, as ARPA did at the birth of the internet.\n\nGNU Kind Communications Guidelines -- astonishingly useful set of specific and positive recommendations. No mention of consequences of violation.\n\nContinue reading Four short links: 23 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/uIqwJlwG8HM/four-short-links-23-october-2018", 
  "title": "Four short links: 23 October 2018"
 }, 
 {
  "content": "A look at the roles of architect and strategist, and how they help develop successful technology strategies for business.There are two jobs in the world that people want to do the most while knowing the least about: architect and strategist.\nI should start by saying this section does not offer a treatise on how to do architecture. I'm offering an overview of my perspective on the field, which I hope is a unique and interesting take on it, in order to provide context for the work at hand: devising a winning technology strategy for your business.\nTechnology systems are difficult to wrangle. Our systems grow in accidental complexity and complication over time. Sometimes we can succumb to thinking other people really hold the cards, that they have the puppet strings we don't.\nThis is exacerbated by the fact that our field is young and growing and changing, and we're still finding the roles we need to have to be successful. To do so, we borrow metaphors from roles in other industries. The term \"data scientist\" was first used in the late 1990s. In 2008 or so, when data scientist emerged as a job title, it was widely ridiculed as a nonjob: the thought that people who just worked with data could be scientists, or employ the rigors of their time-honored methods, was literally laughable in many circles. By 2012, Harvard Business Review published an article by Thomas Davenport and D.J. Patil called \"Data Scientist: The Sexiest Job of the 21st Century.\" Today, it's one of the most desired jobs, with pundits declaiming the terrifying state that we do not have nearly enough of them to tackle our most central technology problems.\nLikewise, the term \"architect\" didn't enter popular usage to describe a role in the software field until the late 1990s. It, too, was ridiculed as an overblown, fancy-pants misappropriation from a \"real\" field. Part of the vulnerability here is that it hasn't always been clear what the architect's deliverables are. We often say \"blueprints,\" but that's another metaphor borrowed from the original field, and of course we don't make actual blueprints.\nWith such origins, and with the subsequent division of the architect role into enterprise architect, solution architect, data architect, and so forth, the lines have blurred further. The result is that decades later, the practice and the art of the architect in technology varies dramatically not only from one company to the next but also from one department and one practitioner to the next.\nSo, we will define the role of the architect in order to proceed from common ground. This is my tailored view of it; others will have different definitions. Before we do that, though, let's cover some historical context that informs how we think of the role.\n\nVitruvius and the principles of architecture\nArchitecture begins when someone has a nontrivial problem to be solved. The product management team states what must be done to solve the problem, and the architect describes how to realize that vision in a system.\nThe first architect of record is a fellow named Vitruvius, who worked as a civil engineer in Rome in the first century B.C. While you may not know his name, during the Renaissance, Leonardo da Vinci popularized the \"Vitruvian Man\" with perfect proportions based on Vitruvius's ideas. Everyone who goes to architecture school learns his work.\nVitruvius is the author of de Architectura, known today as Ten Books on Architecture. It's a delightful, engaging read and had a strong influence on Renaissance artists such as Michelangelo and da Vinci. In it, Vitruvius expands on the three requirements any architecture must demonstrate:\n\nFirmitas\nIt must be solid, firm.\nUtilitas\nIt must be useful, have utility.\nVenustas\nIt must be beautiful, like Venus, inspiring love. This is sometimes translated as \"delightful.\"\n\nIt's a given that we must design a system, including a local software architecture, that actually runs, that is \"solid.\" It may need to run for many years, even decades, and be maintainable to adapt to changes over that time. Solid doesn't mean inflexible. Skyscrapers are built on purpose to sway slightly with the wind, specifically to be more durable. The Sears Tower in Chicago regularly sways between six inches and a foot; taller buildings in America sway as much as four to five feet. Your architectures, and your strategies, must be similarly flexible in order to endure. We'll look at this later when we discuss how to support evolutionary architectures through our strategies.\nIt must also be fit to purpose, which means understanding deeply what the real purpose of the system is and how to manage user expectations. This is supported in real terms through standards and consistent application of conventions, both in the information architecture (i.e., the user experience and design) and within the software construction itself.\nBeauty, for Vitruvius, isn't really in the eye of the beholder. It is about harmony of proportion. One suggestion we can deduce from this for our current purposes is that we must rightsize our architecture and strategy work for the task at hand.\nVitruvius stateswithout ironythat an architect must concern himself with and become educated in several diverse fields of study, such that they find their way into the work. He outlines them in Chapter 1 of de Architectura:\n\n\nSkill in manual labor as well as in theory\n\n\nProclivity and desire for continuous learning\n\n\nA dexterity with tools\n\n\nAn understanding of opticshow the light gets in\n\n\nHistory, such that you can emphasize and not misinterpret signs of cultural significance\n\n\nA strong understanding of philosophy, in order to practice abstract thinking as well as honesty and courtesy\n\n\nPhysics, to help make things sturdy\n\n\nArt, music, theater, drawing, painting, and poetry, to help make things beautiful and well suited to their human purposes\n\n\nMath\n\n\nMedicine\n\n\nAstronomy\n\n\nPolitics\n\n\nHe concludes that absent a degree of education and even lay practice in any one of these areas, one cannot refer to oneself as an architect. These are excellent guides for us in technology today. For those of us concerned with the business of making software and setting the direction for other technologists, to hold ourselves to account in these ways would serve us very well.\nIn a recent conversation I had with Ben Pring, philosopher, noted futurist, and director of The Future of Work Center at Cognizant, he underscored the importance of beauty in software, pointing out that historically our most culturally significant buildings have been not merely adorned but specifically built with beauty in mind as a central, driving narrative. I conclude from this that such foregrounding reinforces in the popular imagination the power of the institutions that build them. I base this conclusion on the preface in the Ten Books, in which Vitruvius writes openly and directly to Emperor Caesar, stating:\n\nBut when I saw that you were giving your attention not only to the welfare of society in general and to the establishment of public order, but also to the providing of public buildings intended for utilitarian purposes, so that not only should the State have been enriched with provinces by your means, but that the greatness of its power might likewise be attended with distinguished authority in its public buildings, I thought that I ought to take the first opportunity to lay before you my writings on this theme. (emphasis mine)\n\nRealizing these broad dicta into an architecture means, I think, finding the concentrations of power, and determining how to best support and ultimately inspire the human factor in the forms we create. I hope once you're done with this book, you'll have some ideas for how to enable and reveal the three facets of firmitas, utilitas, and venustas in your own work.\n\n\nThree concerns of the architect\nWhereas developers are typically focused on delivering working code for a user story within the next two weeks for one system within their one team, architects are concerned with how technology can fulfill business goals given a long-term outlook across a variety of interrelated systems across many teams. It's analogous to a project view versus a portfolio view. They should have their visors raised much higher. The architect is hopefully not concerned with low-level details of the code itself inside one system but is more focused on where data center boundaries are crossed, where system component boundaries are crossed.\nHere's my definition of an architect's work: it comprises the set of strategic and technical models that create a context for position (capabilities), velocity (directedness, ability to adjust), and potential (relations) to harmonize strategic business and technology goals. Notice that in this definition, the role of the architect and technology strategist is not to merely serve the business but to play together. I have been in shops where technology was squarely second fiddle, a subservient order-taking organization to support what was deemed the real business. That's no fun for creative people who have something to contribute. But more importantly, I submit that businesses, now more than ever, cannot sustain such a division and to create greater competitive advantage must work toward integration with co-leadership.\nOver my 20 years in this field, I've come to conclude that there are three primary concerns of the architect:\n\n\nContain entropy.\n\n\nSpecify the nonfunctional requirements.\n\n\nDetermine trade-offs.\n\n\nThere are many different roles that architects legitimately play in organizations. But the primary struggle I have seen comes when they are not focused on a deliverable, on what could be conceived as a \"blueprint.\" Without that focus, they tend to weigh in at project meetings or make declarations informally that can't be remembered or followed. To stay pertinent to the project, and to help guide it in a way that others may not have the purview to do, drawing a line at these boundaries seems to work out pretty well. The definition remains, of course, rather open to interpretation, in grudging deference to the machinations of the real world.\nLet's unpack each of those responsibilities.\n\nContain entropy\nThis viewpoint on the architect's work I learned in a fun conversation over dinner in New York with the very smart and funny Cameron Purdy, the founder of Coherence, who at the time ran Java at Oracle. \"Entropy\" refers to the second law of thermodynamics, which roughly states that systems over time will degrade into an increasingly chaotic state, such that the amount of energy in the system available for work is diminished.\nThe architect defines standards, conventions, and tool sets for teams to use. These are common practices and are generally idiosyncratic to any given organization. As application or solution architects, they help within a system, within an ecosystem, and across an organization to create a common set of practices for developers that help things both go more quickly and be more understandable and maintainable. This is a form of containing entropy. As we mature, we realize that picking one tool or framework or language or platform is not a matter of personal taste but rather a choice with broad ramifications for future flexibility, mergers and acquisitions, training, our ability to hire future supporting teams, and our future ability to directly supportor subvertthe business strategy.\nThose with more business-oriented concerns and technologists cannot ignore each other's fields. Working as a patternmaker and a synthesizer, the architect-as-strategist broadens and ennobles these concerns, creating technology strategies that both are rooted in the causes and concerns of the business and recognize its constraints and opportunities. In collaboration with product management and with colleagues in strategy, business development, finance, and HR, the architect works to ensure there is alignment between the systems, yes, but also between those systems and the organization, and between the organization and its stated aims.\nIn short, for far too long we architects have thought we were in the business of making software. But we're in the business of building a business.\nThe architect who is containing entropy is stating a vision around which to rally, showing a path in a roadmap, garnering support for that vision through communication of guidelines and standards, and creating clarity to ensure efficiency of execution and that you're doing the right things and doing things right.\nI love this definition of containing entropy because it offers something to both the software-minded and the business-minded architect (which I hope are two categories this book will help to collapse). One cannot be successful as an architect without thinking of not only what to do but how to get it done within an organization, which requires knowing why it should matter to someone who isn't a technologist.\nWe often hear of architects with failed dreams of how the system should have been. They are consumed by writing documents, and those documents are subsequently ignored, leading them to give up. Left with only the most informal conversational avenues to offer insufficient direction to teams, they become frustrated and even marginalized.\nKnowing that you're in the business of building a business, and that technology is just an avenue by which you enable that, is a critical first step to being not only useful but powerful as an architect and strategist.\n\n\nSpecify nonfunctional requirements\nKnowing what you're on the hook for, letting others know it, and making sure that it's a concrete deliverable will all go a long way to ensuring your vision is understood and realized.\nProduct management is responsible for specifying what the system must do for the end user. They might state functional requirements in user stories and epics.\nThe nonfunctional requirements are properties of the system that do not necessarily appear directly to the user. They are typically described as the \"-ilities.\" The ones I focus on most are scalability, availability, maintainability, manageability, monitorability, extensibility, interoperability, portability, security, and performance.\nThe architect is responsible for specifying how the system will realize the functional and nonfunctional requirements in its construction. In order to do so, she must write a document that specifies how these will be realized.\nThis document, the architecture definition, serves as the technologist's answer to the blueprint. It should be structured in four broad categories to include business, application, data, and infrastructure perspectives and expressed with clarity and decisiveness, using primarily testable statements as valid propositions (which we'll examine in the next chapter) and math.\nFinding ways to make those expressions concrete and executable is too often overlooked. In addition to writing and publishing a formal architecture definition document to the teams, you can do this by adding nonfunctional requirements to user stories as acceptance criteria.\n\n\nDetermine trade-offs\n\nYou can never try to escape one danger without encountering another. Prudence consists in recognizing the different dangers and in accepting the least bad as good.\nMachiavelli, The Art of War\n\nAs we know, every action produces an equal and opposite reaction. Adding security reduces performance. Sharding and partitioning the database affords greater performance and distribution but creates complexity that is difficult to manage. Adding robust monitoring can generate huge volumes of log data to be stored, rotated, secured, and cleansed. Keeping the design \"simple\" often defers the interests of flexibility until later, where it becomes very expensive.\nThe role of the architect is to see where those challenges may lurk, seek to make them explicit, and make value judgments about how to balance the solutions and the new problems they occasion, under the guidance of the broader business strategy. As English poet John Milton wrote in Paradise Lost, you make \"the darkness visible.\"\nIn short, you're never quite solving a problem. You're only trading it for one that you'd rather have. We solve our need for shelter by assuming a mortgage for which we then must pay. Paul Virilio, the French cultural theorist and philosopher, reminds us lucidly, \"When you invent the ship, you also invent the shipwreck...Every technology carries its own negativity, which is invented at the same time as technical progress\" (Politics of the Very Worst, Semiotexte). Your architecture and strategy work will do well to examine not only how you are addressing the problems you've been given but also what new problems your solutions precipitate.\nAny trade-off eventually reduces to a trade-off of time and money.\nAbsent a strategic mindset, many technologists left to their own devices create what amounts to little more than shopping lists of shiny objects. These can include the latest and most fashionable tech because it's popular or because it might bolster their rsum. We hear this frequently described as \"a solution looking for a problem.\" Moreover, the less shallow or cynically minded among us are still rather prone to chasing exciting technology for its own sake, not unlike a dog chasing a squirrel. Intellectual curiosity is a wonderful thing, a best thing. But to ensure your technology and architecture decisions are truly supportive of the businessthat is, give it the best chance to create competitive advantagethey need to be not shopping lists of shiny objects but squarely strategic.\nSo, let's look at the role of the strategist.\n\n\n\nThe Strategist's Role\n\nStrategy is about getting more power than the starting position would suggest. Strategy is the art of creating power.\nLawrence Freedman, Strategy: A History (Oxford University Press)\n\nThe word \"strategy\" originates from the Greek strategos. The term first appeared in fifth-century Athens as a conflation of the words meaning the expansion of the military general and came to be used to refer to the offices or science of the generalthe general's work. But the word strategy entered general use only at the start of the 19th century in Antoine-Henri Jomini's writing on Napoleon's methods.\nJomini was of Swiss origin; he started out as a banker in Paris, later joined the French army under Napoleon, and eventually got promoted to general. Jomini began writing down Napoleon's methods in such a lucid manner that they came to be published as a book, entitled Treatise on Major Military Operations, in 1803. Jomini's strategies were employed in the U.S. Civil War and eventually taught at West Point Academy. He is considered the founder of modern strategy by many military historians.\nJomini's definition of strategy helpfully divides the word. He writes, \"Strategy decides where to act; logistics brings the troops to this point; tactics decides the manner of execution.\" In other words, means (resources) are allocated and subjected to a method in order to achieve a goal.\nYet definitions of strategy vary. One of the more abstract definitions comes from Sun Tzu, a Chinese general and philosopher and author of The Art of War in 500 B.C. His book was not translated into English until the 20th century, at which point it began serving as a foundational text for guiding military strategies. It entered the popular imagination once it got adapted and marketed for business purposes.\nIn it, he writes, \"Strategy is the art of making use of time and space.\" This is a tall order, and while aesthetically I appreciate the definition, we can break this down further in order to come to something practically executable.\n\nNote\nThe History of Strategy\nIf you're interested in the intellectual history of strategy, its origins, and its evolution from military thought to game theory to business, I highly recommend Lawrence Freedman's \"Strategy: A History\" (Oxford University Press). It's a fascinating read and offers a much richer view than we need here.\n\nFor our purposes, strategy is about determining the problems and opportunities in front of you, defining them properly, and shaping a course of action that will give your business the greatest advantage. Balancing problem solving with creating and exploiting new opportunities through imagination and analysis is the cornerstone of a great strategy.\nEchoing Jomini, we'll say that strategy is about determining the best balance between a set of goals, the method used to achieve them, and the resources available as means. With the current rate of change in business, we can't set it and forget it, expecting that a three- or five-year strategy will go unrevised. At the same time, constant revision amounts to a reactionary collection of tactics, which is no strategy at all.\nMost business strategies will concern themselves with the following:\n\n\nThe goals of the organization\n\n\nThe operating model: processes and how your company conducts its business\n\n\nCulture: the mores and value system, the modes of communication\n\n\nTalent strategy: how you source and retain talent, how you train them\n\n\nFacilities strategy: where you do business, relevant local laws, and cost concerns\n\n\nStrategies should be created at different levels: broad corporate-level strategies, business unit or division strategies, departmental strategies, and portfolio strategies. These will be more or less formal and be revised more frequently according to the climate and what life-cycle stage you find yourself in.\n\nThe Triumvirate: Strategy, Culture, and Execution\n\nCulture eats strategy for breakfast.\nManagement professor Peter Drucker\n\nAny business aims to do one or many of these things:\n\n\nGrow shareholder value\n\n\nGrow earnings per share\n\n\nIncrease revenue\n\n\nManage costs\n\n\nDiversify or create new revenue streams\n\n\nCross-sell more products\n\n\nIncrease market share\n\n\nIncrease share of wallet\n\n\nIncrease yield\n\n\nImprove customer retention\n\n\nReduce product error/defect rates\n\n\nImprove safety\n\n\nImprove time to market/speed of operations\n\n\nGrow through acquisition\n\n\nOf course, there are different emphases at different times. To achieve these aims, broadly speaking, the strategist asks these questions:\n\n\nAre resources devoted to the right areas, to the most important customers?\n\n\nAre we creating products and services that can thrive in a market in different time horizons?\n\n\nWhere should we spend money? Where should we cut costs?\n\n\nWhere do skills need to be added or strengthened?\n\n\nWhere can productivity be improved?\n\n\nWhat culture, attitude, and skills are required?\n\n\nMany companies have a chief strategy officer or VP of corporate strategy. Strategy season frequently begins in the spring, giving this person and her team a couple of months to prepare a deck to present to the executive leadership team in the late summer. This will be discussed, revised, and eventually approved and used as input for budget season, which begins in the fall and continues until the budget for the following year is approved. We in technology tend to like to see our ideas realized moments after we have them. Being aware of this calendar and corporate planning process will help you plan for adding any big-ticket items to the slate in time for them to receive the necessary attention, support, and budget allocations.\nThat said, the evolution of Agile software methods, the preponderance of \"disruptive\" startups, and a growing global economy have all aligned variously to dilute the formality and rigidity of the strategist's role in such a process, leading her to rely more on regular conversations with the executive team and create reports with tighter scopes on an ongoing basis.\nDepending on her level of power and position within the organization, the strategist finds herself concerned with some or all of the following:\n\n\nIdentifying business development opportunities, such as partnerships, joint ventures, cooperative arrangements with competitors, and the like\n\n\nFinding, proposing, and validating mergers and acquisition opportunities\n\n\nBuilding strategic capabilities within certain areas of the organization, such as helping create a sustainable AI practice in the face of growing trends\n\n\nPerforming research based on data to recommend long-term directions for the company (generally 13 years)\n\n\nThis last one is very common and how many strategists are trained as consultants entering the field at the venerable strategy firms such as Bain, Boston Consulting Group (BCG), and McKinsey. They likely work with business analysts, marketing, sales, technology, and operations teams in a cross-functional working group to develop hypotheses for how the business climate might be enabling or impinging upon their competitive advantage and how they should define a goal and direction and allocate resources to win in the marketplace.\nAccording to one McKinsey report, 40% of strategists responding to their survey are most focused on \"using fact-based analysis to spot industry shifts and to understand their own companies' sources of competitive advantage as a foundation for clear, differentiated strategies.\"\nBut spending months researching and creating data-driven decks is no longer enough. Because the world is moving so fast, the traditional strategist has taken the driver's seat in building capabilities. As the walls between business and technology continue to fold in on each other, the strategist may well find himself leading a team of data scientists to create an analytics platform to help themselves and their customers gain precious insights into their business operations. My colleague Balaji Krishnamurthy, the VP of strategy at Sabre Hospitality, who was previously in strategy roles at McKinsey and LinkedIn, offers this observation:\n\nTo be a good strategist, you need to be ready to deal with ambiguity. You need to be ready to pivot. You must form a hypothesis quickly about what must be done, then synthesize a lot of data. You must then see options and possibilities available, determine a goal, and present your findings clearly with a recommendation on how to allocate resources to achieve that goal.\n\nUltimately, companies are looking to grow and gain some distinctive competitive advantage. They can do this through technical innovation properly applied to real-world business problems. One assertion of this book is that the roles of chief architect and chief strategist are more blurred, and more aligned, than ever and that their mutual understanding of each other's concerns and methods will be an increasingly important driver for winning organizations.\nLearn from your executive and product leadership teams what areas of focus they have for their business strategy and product roadmaps, so you can be prepared to match your technology to them.\nFor example, if your business is in cost-cutting mode, as companies tend to be when revenue is soft or they're preparing for an IPO, then your technology strategy should match. You can do that by examining the people angle: can you move workers or ramp down in expensive cities in order to hire programmers in lower-cost development centers? Can you examine your delivery and release processes to add automation and reduce manual labor there? Can you use free and open source libraries in place of expensive commercial software? These are examples from people, processes, and technical perspectives of how you can map your technology strategy to the business strategy.\nA strategy deck is analogous to an architecture definition document for the organization. Neither will achieve the desired aims if you assume it lives in a vacuum.\nThe culture of your organization comprises your stated principles and to a far greater extent, the actual lived principles as reflected by the attitudes, communication styles, and behaviors of your teams. If your teams are territorial and competitive, an integrative platform strategy must identify and address that challenge.\nFinally, your teams must be ready and capable of executing on your strategy. A strategy deck that states lofty, exciting aims will fail if it also doesn't include diligent, consistent execution and clear metrics to measure its success. This triumvirate is illustrated in Figure 1.\n\nFigure 1. The triumvirate dominating forces of strategy, culture, and execution\n\nFind ways to work with your leadership and across teams to ensure all of these forces are aligned. A good first step for doing so is to create two versions of the strategy: one that provides an honest and detailed examination of all three factors to share with the executive team and another shorter version that communicates only the changes you're driving in a way that you can share publicly with teams. In long-range planning, there are financial, business transaction, and personnel matters that obviously can't be disclosed.\n\n\nContinue reading How architecture evolves into strategy.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/1sxqaAUdXAQ/how-architecture-evolves-into-strategy", 
  "title": "How architecture evolves into strategy"
 }, 
 {
  "content": "Perl in the Browser, Pharo Programming, Program Synthesis, and Raster Vision\n\nWebPerl -- run Perl in the browser, via WebAssembly and EmScripten. PerlMonks discussion. (via Hacker News)\n\nPharo -- a pure object-oriented programming language and a powerful environment focused on simplicity and immediate feedback (think IDE and OS rolled into one). SmallTalk's ideas are ready for a comeback!\n\nType-Driven Program Synthesis -- The talk will present two applications of type-driven synthesis. The first one is a tool called Synquid, which creates recursive functional programs from scratch given a refinement type as input. Synquid is the first synthesizer powerful enough to automatically discover programs that manipulate complex data structures, such as balanced trees and propositional formulas. The second application is a language called Lifty, which uses type-driven synthesis to repair information flow leaks. In Lifty, the programmer specifies expressive information flow policies by annotating the sources of sensitive data with refinement types, and the compiler automatically inserts access checks necessary to enforce these policies across the code.\n\n\nRaster Vision -- open source framework for deep learning on satellite and aerial imagery.\n\n\nContinue reading Four short links: 22 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/vKWsXWHDDMg/four-short-links-22-october-2018", 
  "title": "Four short links: 22 October 2018"
 }, 
 {
  "content": "Our most-used Python resources will help you stay on track in your journey to learn and apply Python.We dove into the data on our online learning platform to identify the most-used Python resources. These are the items our platform subscribers regularly turn to as they apply Python in their projects and organizations.\nIntroduction to Python  Jessica McKellar teaches you Pythons core concepts and data types through hands-on exercises and useful projects.\nPython for Data Analysis, 2nd Edition  Wes McKinney shares practical case studies that show you how to solve a broad set of data analysis problems effectively. Youll learn the latest versions of pandas, NumPy, IPython, and Jupyter in the process.\nLearning Python, 5th Edition  Mark Lutz leads you through an in-depth, hands-on introduction to the core Python language. Its an ideal way to begin, whether youre new to programming or a professional developer versed in other languages.\nDeep Learning with Python  Franois Chollet introduces the field of deep learning using the Python language and the powerful Keras library. This book builds your understanding through intuitive explanations and practical examples.\nLearn Python 3 the Hard Way: A Very Simple Introduction to the Terrifyingly Beautiful World of Computers and Code, 1st Edition  Zed A. Shaw helps you learn Python using 52 exercises. Read them. Type their code precisely. Fix your mistakes. Watch the programs run.\nFluent Python  Luciano Ramalho takes you through Pythons core language features and libraries, and shows you how to make your code shorter, faster, and more readable at the same time.\nAutomate the Boring Stuff with Python  Al Sweigart teaches simple programming skills to automate everyday computer tasks.\nPython Crash Course  Eric Matthes takes you through a fast-paced, thorough introduction to programming with Python that will have you writing programs, solving problems, and making things that work in no time.\nEffective Python: 59 Specific Ways to Write Better Python  Brett Slatkin helps you master a truly Pythonic approach to programming, bringing together 59 Python best practices, tips, and shortcuts, and explaining them with realistic code examples.\nPython Cookbook, 3rd Edition  Packed with practical recipes written and tested with Python 3.3, this unique cookbook by David Beazley and Brian K. Jones is for experienced Python programmers who want to focus on modern tools and idioms.\nContinue reading 10 top Python resources on OReillys online learning platform.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/fXqQkf-TPDs/10-top-python-resources-on-oreillys-online-learning-platform", 
  "title": "10 top Python resources on O\u2019Reilly\u2019s online learning platform"
 }, 
 {
  "content": "PDF to Data Frame, Clever Story, Conceptual Art, and Automatic Patch Synthesis\n\nCamelot -- Python library that extracts tables of data from PDF documents, returning them as Pandas frames.\n\nSTET -- short story told via footnotes, editorial markup, and more. Magnificent! (via Cory Doctorow)\n\nSolving Sol -- interpreting a conceptual artist's art as instructions, reframed as an AI problem. Clever!\n\nHuman-Competitive Patches with Repairnator -- Repairnator is a bot. It constantly monitors software bugs discovered during continuous integration of open source software and tries to fix them automatically. If it succeeds to synthesize a valid patch, Repairnator proposes the patch to the human developers, disguised under a fake human identity. To date, Repairnator has been able to produce five patches that were accepted by the human developers and permanently merged in the code base.\n\n\nContinue reading Four short links: 19 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/c7Jkx08PuH4/four-short-links-19-october-2018", 
  "title": "Four short links: 19 October 2018"
 }, 
 {
  "content": "Git Playbook, Lessons Learned, Neural NLP, and Landscape Generation\n\nFlight Rules for Git -- the hard-earned body of knowledge recorded in manuals that list, step-by-step, what to do if X occurs and why. Essentially, they are extremely detailed, scenario-specific standard operating procedures. What to do after you shoot yourself in the foot in interesting ways with Git.\n\nLessons Learned from Creating a Rich-Text Editor with Real-Time Collaboration -- This article describes how we approached the problem and what challenges we had to overcome in order to provide real-time collaborative editing capable of handling rich text. Check it out if you are interested in: learning what problems you may face when implementing real-time collaborative editing, building a rich-text editor with support for real-time collaboration, and how we approached collaborative editing in CKEditor 5.\n\n\nA Review of the Recent History of Natural Language Processing -- This post will discuss major recent advances in NLP focusing on neural network-based methods.\n\n\nLandscape -- software that builds the Cloud-Native Computing Foundation's landscape of products.\n\nContinue reading Four short links: 18 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/4DCbvzxXZYU/four-short-links-18-october-2018", 
  "title": "Four short links: 18 October 2018"
 }, 
 {
  "content": "OReillys new survey reveals the latest operations salary trends, and the skill sets that will keep your operations career on track.OReilly conducted a recent survey[1] of operations professionals, and the results offer useful information and insights to empower your career planning. As youd expect, the survey revealed that respondents put emphasis on their salaries when evaluating their careers, but they also pay close attention to company and team attributes, job activities, role responsibilities, and evolving skill set requirements.\nHow operations salaries add up\nSurvey results show that in 2018, the median annual salary for operations professionals clocks in at $90,000. Salary increases with age and experience: someone with more than 20 years of experience can earn a median income of around $123,000.\n\nFigure 1. Operations salaries by years of experience. Image credit: O'Reilly.\n\nThe company, team, and industry all make a difference\nThe larger the company, the more you should expect to earn. For example, the median salary for companies employing two-to-100 people is slightly more than $78,000. Jump to companies with more than 10,000 employees and the average income rises to $114,000. Interestingly, the age of a company is not a huge factor in determining compensation.\nTeam size, however, does make a difference among survey respondents. The general trend is that the larger the team size, the higher the median salary. Keep in mind that joining a bigger team does not necessarily equate to a pay increase. Larger teams usually mean more senior team members, team leads, and an established hierarchy. Increased responsibility generates increased compensation.\nThe industry where you work does affect compensation. About a third of survey respondents work in the software industry, and they report a median salary of $95,000. Operations professionals working for high-paying health care and medical companies see a median salary of $113,000.\nWhere time spent impacts dollars earned\nIt seems the more coding you do as part of your job, the less you earn. For survey respondents who code one-to-three hours per week, the median salary is around $94,000. Spend 20 hours or more per week on code tasks and the median salary drops to $82,000. You can attribute this to several factors. One, as you become more senior in your organization, increased responsibilities leave less time for coding. And two, if you are part of an organization with many coders, both entry-level staff and interns bring down the median salary.\nFor those not fond of attending meetings, heres a survey result you might not want to see: the more time you spend in meetings, the higher the median salary. Those who spend more than 20 hours per week in meetings have a median salary of $140,000. Of course, meetings can be a proxy for responsibility, so booking yourself into every optional meeting will not increase salary automatically.\nSpeaking the same programming language\nScripting languages are the most popular programming languages among respondents, with Bash being the most used (66% of respondents), followed by Python (63%), and JavaScript (42%).\nGo is used by 20% of respondents, and those who use Go tend to have one of the higher median salaries at $102,000, similar to LISP and Swift. This could be related to the types of companies that are pushing these programming languages. Google and Apple, for example, are very large companies and, as noted, salary and company size are related.\nAnd what about the operating system in which respondents work? Linux tops the charts at 87% usage. Windows is also used frequently (63%), often as a mix between workstations and servers, and in some cases as a front end for Linux/Unix servers.\nEducation pays\nComputer science, mathematics, statistics, and physics are the top fields of study for operations professionals. Advanced degrees do have a positive impact on salary. The median salary among respondents for those with a masters is $82,000, whereas a doctorate garners a median salary of $98,000.\nPlanning your next operations career move\nOne third of survey respondents agree that the next best step to career advancement is to learn a new skill or technology. This makes sense, as the technology landscape is evolving quickly and you need to acquire new skills to keep up.\nWanting to work on more interesting or important projects is a motivator for career change among some respondents (25%), as is the desire to move into leadership roles (15%). Only 12% of respondents want to switch companies.\nOther things respondents keep top of mind when pondering their operations career paths include non-monetary compensation such as job flexibility, work-life balance, location, and company culture.\nLooking for more data to guide your career development? Download the 2018 Annual IT/Ops Salary Survey for free.\n\n\n\n[1] Operations professionals answered a range of questions about their current roles. More than 1,300 respondents from 70-plus countries participated in the survey.\n\n\nContinue reading What operations professionals need to know to fuel career advancement.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/wBROFxW_Jm0/what-operations-professionals-need-to-know-to-fuel-career-advancement", 
  "title": "What operations professionals need to know to fuel career advancement"
 }, 
 {
  "content": "Reservoir Computing, ProxyJump, SID Sequencer, and 2KB AI\n\nMEMS Neuromorphic Computing -- the construction of the first reservoir computing device built with a microelectromechanical system (MEMS). [...] [T]he neural network exploits the nonlinear dynamics of a microscale silicon beam to perform its calculations. The group's work looks to create devices that can act simultaneously as a sensor and a computer using a fraction of the energy a normal computer would use. Early-stage research but an interesting direction for the future of hardware.\n\nSSH ProxyJump -- its somewhat common to have whats known as a jump host serve as an SSH gateway to a remote network. You use SSH to log into the jump host (or jump server) and from there use SSH to log into an internal host thats not directly accessible from the internet. This useful utility makes it a one-step action.\n\nBooting defMON -- an introduction to an absolutely wild low-level sequencer for the C64 SID chips.\n\nMachine Learning on 2KB of RAM -- This paper develops a novel tree-based algorithm, called Bonsai, for efficient prediction on IoT devicessuch as those based on the Arduino Uno board having an 8-bit ATmega328P microcontroller operating at 16 MHz with no native floating point support, 2KB RAM, and 32KB read-only flash. (jaws drop)\n\nContinue reading Four short links: 17 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/47pkIgQDqTk/four-short-links-17-october-2018", 
  "title": "Four short links: 17 October 2018"
 }, 
 {
  "content": "Common Sense, Photorealistic Rendering, Logic Game, and the Grey-hat Patcher\n\nTeaching Machines Common Sense Reasoning (DARPA) -- To focus this new effort, MCS will pursue two approaches for developing and evaluating different machine common sense services. The first approach will create computational models that learn from experience and mimic the core domains of cognition as defined by developmental psychology. [...] The second MCS approach will construct a common sense knowledge repository capable of answering natural language and image-based queries about common sense phenomena by reading from the web.\n\n\nPhysically Based Rendering -- a textbook that describes both the mathematical theory behind a modern photorealistic rendering system as well as its practical implementation.\n\nQED -- a short interactive text in propositional logic arranged in the format of a computer game.\n\n\nA Mysterious Grey-Hat is Patching MicroTik Routers -- \"I added firewall rules that blocked access to the router from outside the local network,\" Alexey said. \"In the comments, I wrote information about the vulnerability and left the address of the @router_os Telegram channel, where it was possible for them to ask questions.\" More helpful than some corporate IT departments...\n\nContinue reading Four short links: 16 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/oQjKIfQFA70/four-short-links-16-october-2018", 
  "title": "Four short links: 16 October 2018"
 }, 
 {
  "content": "Create a coherent BI strategy that aligns data collection and analytics with the general business strategy.Results-based leaders rely on having the right information at the right time in order to support operational decision-making. Thats why decision-makers consider business intelligence their top technology priority. They recognize the instrumental role data plays in creating value and see information as the lifeblood of the organization. They then use actionable insights to confidently and consistently lead by delivering results that count.\nThe business intelligence (BI) and data science industries have spent the last couple decades making data access easier, analytic capability more comprehensive, and platforms more scalable. Yet, despite pouring billions of dollars into BI initiatives, executives often come up empty-handed when they reach for the information they need to make well-informed decisions. Executives fail to fully capitalize on BIs promise of turning actionable insights into real business value when BI efforts arent planned or executed effectively. These problems are further compounded as companies move to adopt more sophisticated data science and AI. To achieve the results that leaders are looking for, organizations must create a coherent BI strategy that aligns data collection and analytics with the general business strategy.\nOur experience shows that by focusing on four actionable steps, or imperatives, we can empower business leaders to adequately address planning and execution challenges to build a decision support competency that works.\nStep 1: Unify\nWhat we believe influences how we behave, and unifying your organization begins with aligning many unique and often divergent perspectives across different business divisions on business intelligence and analytics. Senior leaders across an organization must collaborate efficiently for BI to be successful.\nAll too often, requests for information from the business go unanswered, as different siloed departments trip over themselves to coordinate inter-departmental cooperation. Technical nuances around data and data wrangling are often misunderstood and miscommunicated because practitioners routinely fail to understand key business requirements. Business leaders need to look for data science candidates with keen technical, analytic, and business acumen (full disclosure: Michael Li is the founder and CEO of The Data Incubator) to unify their BI efforts between technical and non-technical parts of the business.\nBusiness intelligence is a business initiative, not a tech project. Its an ongoing effort across an entire organization to improve its decision-making ability to create and maximize value. There is no finish line. Adopting this attitude across every business division in your organization is a prerequisite for effective collaboration and a necessity for creating the kind of cross-functional alignment needed for BI success.\nStep 2: Simplify\nComplexity is wreaking havoc on businesses and making it increasingly difficult for decision-makers to create value. Analytics works best when the process of moving from great idea to actionable insight is fast, focused, and uncomplicated.\nTo simplify your BI efforts, start by building key alliances with critical stakeholders in different lines of business within your organization. Now more than ever, CEOs rely on CIOs and CDOs to drive an organizations value-creation agenda, and that makes effective collaboration between business and IT absolutely critical to BI success. The days of an ivory-towered BI detached from real business operations are over. It is vital that business leaders work overtime to bridge the all-too-common communication, trust, and understanding gaps.\nThen, secure executive buy-in and the financial resources you need for your efforts by building your capability one incremental step at a time and demonstrating real value every step of the way. When building your BI capability, always start with the existing technology you already have. Most organizations have already made significant investments in tools and infrastructure and have built important intellectual capital that only comes with experience and time. Prove that it cant or wont work before requesting additional funds for new technology.\nFinally, when it comes to providing decision-makers with the information they need to do their jobs, minimizing time-to-results is critical. This means striking the right balance between governing and enabling the business to perform without hindering innovation and creativity.\nStep 3: Amplify\nSkeptics and naysayers exist in every organization. They prefer the status quo, resist change, and make comments like, weve been down this road before, and Ill believe it when I see it. At best, theyre stubborn demanders of proof, willing to believe only when presented with concrete results. At worst, theyre obstructionistspreventing business intelligence initiatives from realizing their full potential.\nAs BI evolves from traditional reporting and descriptive analytics toward data science and AI, many practitioners fear that new capabilities will make their skill sets obsolete.Fighting new initiatives is, perhaps, a natural preservation instinct. The prevalence of naysayers may also be symptomatic of cultural biases in the institution. Deloitte refers to it as the inertia of good intentionspersonal behavior created by institutional routines, obligations, and pressures that actually hold many back (unsuspectingly) from delivering the kind of value their organizations need. Left unattended, the culture of most organizations can marginalize BI initiatives to the point of limited and unacceptable return.\nYou can avoid the negative impact of skeptics and naysayers as well as a culture of mistrust by establishing organizational awareness and building excitement around BI, analytics, and data science initiatives. To amplify means to evangelize.\nFor instance, large enterprises often create a Data Science Competency Center or AI Center of Excellence, which helps lead the effort to modernize analytics. These evangelists define the data science and AI practices for the firm and are responsible for elevating the general analytical skill level of the entire organization. Fortune 500 Data Science Centers of Excellence are hosting in-depth trainings in data and AI to help bridge the skills gap between the advanced data science practitioners of their organizations and the typical rank-and-file analysts.\nStep 4: Qualify\nBusiness intelligence is a journeya process of continuous improvement meant to adapt and evolve so that business leaders can give intelligent responses to an ever-changing and dynamic business environment. After all, what decision-makers need to monitor and evaluate the business today will change tomorrow. The only way for a business to keep pace is for its reporting and analytics capabilities to keep pace as well.\nToday, few firms qualify success properly. They dont proactively monitor and measure BI performance against end-user expectations and real business outcomes, so they cant effectively evolve.\nEnsure that you focus adequate attention on active monitoring, evaluation, and adjustment of your organizations business intelligence capabilities so theyre always aligned with the business needs and always responsive to stakeholder expectations.\nAs companies are looking toward growing their BI, analytics, and data science departments, management is demanding results. All too often, analytics projects fall short because leaders fail to understand the key elements of a successful analytics strategy while creating one. In order to plan and execute successful business intelligence efforts, leaders in this area must adopt these imperatives. By focusing your organizations BI initiative around simplifying, unifying, amplifying, and qualifying business intelligence within the whole organization, youll be able to make smarter business decisions, deliver successful results, and keep your firm ahead of the competition.\nContinue reading 4 imperatives for making business intelligence work.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/yPvWxL_U3vA/4-imperatives-for-making-business-intelligence-work", 
  "title": "4 imperatives for making business intelligence work"
 }, 
 {
  "content": "Robots, Cryptocurrencies, Bayes, and Brains\n\nWhat People See in a Robot (YouTube) -- In a study using 24 robots selected from this three-dimensional appearance space, I then show that the different dimensions separately predict inferences people make about the robots affective, social-moral, and physical capacities. (via RoboHub)\n\nCrypto is the Mother of All Scams and (Now Busted) Bubbles While Blockchain Is The Most Over-Hyped Technology Ever, No Better than a Spreadsheet/Database (Nouriel Roubini) -- Roubini's testimony to the Hearing of the U.S. Senate Committee on Banking, Housing and Community Affairs on Blockchains. It is clear by now that Bitcoin and other cryptocurrencies represent the mother of all bubbles, which explains why literally every human being I met between Thanksgiving and Christmas of 2017 asked me first if they should buy them. [...] A chart of Bitcoin prices compared to other famous historical bubbles and scamslike Tulip-mania, the Mississippi Bubble, the South Sea Bubbleshows that the price increase of Bitcoin and other crypto junkcoins was 2X or 3X bigger than previous bubbles, and the ensuing collapse and bust as fast and furious and deeper. [...] Actually calling this useless vaporware garbage a shitcoin is a grave insult to manure that is a most useful, precious, and productive good as a fertilizer in agriculture. It's all quotable. Read it.\n\nBayes' Theorem in the 21st Century -- I recently completed my term as editor of an applied statistics journal. Maybe a quarter of the papers used Bayes theorem. Almost all of these were based on uninformative priors, reflecting the fact that most cutting-edge science does not enjoy Five-Thirty-Eight-level background information. Are we in for another Bayesian bust?\n\n\nNumenta's New Theory -- research paper, talk, NYT story. Will be interesting to see how this fares in peer review.\n\nContinue reading Four short links: 15 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/2knnav5UQoU/four-short-links-15-october-2018", 
  "title": "Four short links: 15 October 2018"
 }, 
 {
  "content": "Activity Alert, JavaScript Visualizations, OT vs. CRDT, and Senior Engineering\n\nPublicly Available Tools Seen in Cyber Incidents Worldwide (US-CERT) -- The tools detailed in this activity alert fall into five categories: remote access trojans (RATs), webshells, credential stealers, lateral movement frameworks, and command and control (C2) obfuscators. This activity alert provides an overview of the threat posed by each tool, along with insight into where and when it has been deployed by threat actors. Measures to aid detection and limit the effectiveness of each tool are also described. The activity alert concludes with general advice for improving network defense practices.\n\n\nMuze -- Tableau-like visualizations in JavaScript. Open source (MIT).\n\nReal Differences between OT and CRDT for Co-Editors -- key CRDT design issues include designing CRDT-special data structures and schemes for representing and manipulating object sequences, searching and executing identifier-based operations in the object sequence, and conversions between internal identifier-based operations and external position-based operations, which collectively deal with both application-specific and concurrency issues in co-editing. This approach has induced a myriad of CRDT-specific challenges and puzzles, such as the correctness of key CRDT data structures and functional components, tombstone overhead, variable and lengthy identifiers, inconsistent-position-integer-ordering and infinite loop flaws, position-order-violation puzzles, and concurrent-insert-interleaving puzzles.\n\n\nWhat's a Senior Engineer's Job? (Julia Evans) -- I want to talk here about the work that a senior engineer does.\n\n\nContinue reading Four short links: 12 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/yOo_RgLcV9o/four-short-links-12-october-2018", 
  "title": "Four short links: 12 October 2018"
 }, 
 {
  "content": "This collection of serverless resources will get you up to speed on the basics and best practices.Whether youre just getting started with serverless or you have previous experience, youll find something useful on this list of serverless resources.\nThe items on this list were curated by OReillys editorial experts.\nGetting started with serverless\nUse this introductory material to get up to speed on the basics of serverless.\nAn Introduction to Serverless  In this short overview, Mike Roberts introduces the concepts behind serverless architectures.\nWhat is Serverless?  Mike Roberts and John Chapin take you through the serverless landscapeparticularly the design considerations, tooling, and approaches to operational management you need to make it work.\nLearning Path: Getting Started with Serverless  Sam Newman demonstrates the benefits of serverless and provides overviews of function as a service (FaaS) and back end as a service (BaaS).\nImplementing serverless\nThese resources outline best practices for incorporating serverless into your organization.\nLearning Path: Migrating Microservices to Serverless  Sam Newman guides you through the many serverless frameworks that are currently available so you can choose the one thats best for your organization.\nServerless Ops  Michael Hausenblas explores several use cases where serverless is a great fitprimarily short-running, stateless jobs in event-driven architectures found in mobile or IoT applications.\nGoing Serverless: Security Outside the Box  Jack Naglieri and Austin Byers explore tools and techniques for successfully building, deploying, and debugging serverless security applications.\nLessons Learned from Operating a Serverless-like Platform at Scale  Sangeeta Narayanan shares insights from operating Netflixs customizable API, which allows the creation of optimized experiences on 1,000+ devices through a serverless-like platform and experience.\nBuilding and Running Serverless Data Pipelines on AWS  Mike Roberts walks through a real-life example of a platform that was rearchitected to provide increased data capacity, reduced cost, and an improved development cycle time.\nMicroservice Orchestration for Serverless Computing  Cathy Zhang explains how service graphs address the challenge of creating and managing microservice applications.\nContinue reading Learn about serverless with these books, videos, and tutorials.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/ic952FeHz0w/learn-about-serverless-with-these-books-videos-and-tutorials", 
  "title": "Learn about serverless with these books, videos, and tutorials"
 }, 
 {
  "content": "Kristian Hammond maps out simple rules, useful metrics, and where AI should live in the org chart.Continue reading Bringing AI into the enterprise: A functional approach to the technologies of intelligence.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/IOHgpGBwz6c/bringing-ai-into-the-enterprise-a-functional-approach-to-the-technologies-of-intelligence", 
  "title": "Bringing AI into the enterprise: A functional approach to the technologies of intelligence"
 }, 
 {
  "content": "Supasorn Suwajanakorn discusses the possibilities and the dark side of building artificial people.Continue reading Building artificial people: Endless possibilities and the dark side.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/LgIs8S8lSQA/building-artificial-people-endless-possibilities-and-the-dark-side", 
  "title": "Building artificial people: Endless possibilities and the dark side"
 }, 
 {
  "content": "Decentralized Applications, Global Startups, Better Shuffling, and Prolog Text\n\nDecentralized Applications (MIT) -- interesting course to be taught by Robert T Morris. The goal of 6.S974 is to understand recent efforts in decentralized applications, to learn what the main design trade-offs are, and to identify areas for new research. My spidey-sense is tingling. This has all the hallmarks of one of those courses whose graduates build the next wave of companies and research areas.\n\nAmerica Is Losing Its Startup Edge -- ignore the use of percentages and Decline of Roman^W American Empire alarmism, it's the rise of the rest of the world that's fascinating here. While it is true that venture-capital investment in the U.S. continues to rise, having reached more than $90 billion in 2017, such investment is growing even faster in other parts of the world, expanding by nearly 375%more than twice the 160% increase here. China saw the largest jump, its share expanding from 4% of global venture investment in 2005 to a nearly a quarter of it by 2017.\n\n\nPlaylist Shuffle -- This paper proposes a novel approach at shuffling a looping sequence that minimizes caveats of naive solutions, keeps computation low, and offers a high degree of variance. [...] The problem is how to repeatedly shuffle a cyclic list and avoid too close and too far duplicates.\n\n\nArt of Prolog, 2E -- this 1994 classic is now an open access title, free PDF download. Prolog is rational AI magic, while deep learning is intuitive AI magic.\n\nContinue reading Four short links: 11 October 2018.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/TcF-3D37JNo/four-short-links-11-october-2018", 
  "title": "Four short links: 11 October 2018"
 }, 
 {
  "content": "Cassie Kozyrkov shares machine learning lessons learned at Google and explains what they mean for applied data science.Continue reading The missing piece.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/rfebKlLLcsE/the-missing-piece-ai-uk-18", 
  "title": "The missing piece"
 }
]